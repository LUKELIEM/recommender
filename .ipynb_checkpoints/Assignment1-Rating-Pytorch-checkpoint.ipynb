{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss\n",
    "\n",
    "def readCSV(path):\n",
    "  f = open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')\n",
    "    \n",
    "def calc_model_stats(pred,label):\n",
    "    \n",
    "    TP,FP,TN,FN = calc_metrics(pred,label)\n",
    "\n",
    "    # print(\"Stats\")\n",
    "    # print(TP,FP,TN,FN)\n",
    "\n",
    "    # print(\"Predict N: {} ({}%)\".format(TN+FN,(TN+FN)/(TP+TN+FP+FN)))\n",
    "    # print(\"Predict P: {} ({}%)\".format(TP+FP,(TP+FP)/(TP+TN+FP+FN)))\n",
    "\n",
    "    accuracy, TPR, TNR, BER = calc_error_rates(TP, FP, TN, FN)\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    # print(\"TPR: {}\".format(TPR))\n",
    "    # print(\"TNR: {}\".format(TNR))\n",
    "    # print(\"BER: {}\".format(BER))\n",
    "    \n",
    "    return\n",
    " \n",
    "def calc_metrics(predictions, labels):\n",
    "    # Calculate True positives, false positives, etc.\n",
    "\n",
    "    TP_ = numpy.logical_and(predictions, labels)\n",
    "    FP_ = numpy.logical_and(predictions, numpy.logical_not(labels))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(labels))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(predictions), labels)\n",
    "\n",
    "    TP=sum(TP_)\n",
    "    FP=sum(FP_)\n",
    "    TN=sum(TN_)\n",
    "    FN=sum(FN_)\n",
    "    \n",
    "    return TP,FP,TN,FN\n",
    "\n",
    "def calc_error_rates(TP, FP, TN, FN):\n",
    "    # Calculate accuracy, TPR, TNR and BER\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1.0 - (TPR+TNR)/2\n",
    "    \n",
    "    return accuracy, TPR, TNR, BER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    itr = 0\n",
    "    \n",
    "    def __init__(self, n_user, n_item, k=1, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        super(MF, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        # gammas (users and items)\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "        \n",
    "        # alpha and betas (users and items)\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        user_id = train_x[:, 0]\n",
    "        item_id = train_x[:, 1]\n",
    "        vector_user = self.user(user_id)\n",
    "        vector_item = self.item(item_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + bias_user + bias_item)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "        \n",
    "        prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
    "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "        total = loss_mse + prior_user + prior_item + prior_bias_user + prior_bias_item\n",
    "        for name, var in locals().items():\n",
    "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
    "                self.writer.add_scalar(name, var, self.itr)\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_id and item_id --> user_idx, item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      "userID    200000 non-null object\n",
      "bookID    200000 non-null object\n",
      "rating    200000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>bookID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u79354815</td>\n",
       "      <td>b14275065</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u56917948</td>\n",
       "      <td>b82152306</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u97915914</td>\n",
       "      <td>b44882292</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u49688858</td>\n",
       "      <td>b79927466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u08384938</td>\n",
       "      <td>b05683889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID     bookID  rating\n",
       "0  u79354815  b14275065       4\n",
       "1  u56917948  b82152306       5\n",
       "2  u97915914  b44882292       5\n",
       "3  u49688858  b79927466       5\n",
       "4  u08384938  b05683889       2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/cse258/assignment1/train_Interactions.csv\")\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat Interactions based on (user_idx, book_idx, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7170 ['b14275065', 'b82152306', 'b44882292']\n",
      "11357 ['u79354815', 'u56917948', 'u97915914']\n"
     ]
    }
   ],
   "source": [
    "book_ids = list(data['bookID'].unique())\n",
    "user_ids = list(data['userID'].unique())\n",
    "\n",
    "print(len(book_ids), book_ids[:3])\n",
    "print(len(user_ids), user_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids.index('u08384938')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/train_interact_reformatted.csv\"\n",
    "\n",
    "reviews = open(fname, 'w')\n",
    "reviews.write('userIDX' + ',' + 'bookIDX' + ',' + 'rating'+ '\\n')\n",
    "\n",
    "i = 0\n",
    "for index, row in data.iterrows():\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    reviews.write(str(user_ids.index(row['userID'])) + ',' \\\n",
    "                  + str(book_ids.index(row['bookID'])) + ',' \\\n",
    "                  + str(row['rating'])+ '\\n')\n",
    "reviews.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/user_reformatted.csv\"\n",
    "\n",
    "file = open(fname, 'w')\n",
    "file.write('userID' + ',' + 'userIDX' '\\n')\n",
    "\n",
    "i = 0\n",
    "for id in user_ids:\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    file.write(str(user_ids.index(id)) + ',' + id + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/book_reformatted.csv\"\n",
    "\n",
    "file = open(fname, 'w')\n",
    "file.write('bookID' + ',' + 'bookIDX' '\\n')\n",
    "\n",
    "i = 0\n",
    "for id in book_ids:\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    file.write(str(book_ids.index(id)) + ',' + id + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reformatted interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      "userIDX    200000 non-null int64\n",
      "bookIDX    200000 non-null int64\n",
      "rating     200000 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.6 MB\n",
      "11357 7170\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/cse258/assignment1/train_interact_reformatted.csv\")\n",
    "data.info()\n",
    "data.head()\n",
    "\n",
    "n_user = len(data['userIDX'].unique())\n",
    "n_item = len(data['bookIDX'].unique())\n",
    "\n",
    "print(n_user,n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1921</td>\n",
       "      <td>391</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3764</td>\n",
       "      <td>3057</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1938</td>\n",
       "      <td>2782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1812</td>\n",
       "      <td>563</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3661</td>\n",
       "      <td>6903</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userIDX  bookIDX  rating\n",
       "0     1921      391       4\n",
       "1     3764     3057       5\n",
       "2     1938     2782       3\n",
       "3     1812      563       3\n",
       "4     3661     6903       4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Dataset into Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190000.000000</td>\n",
       "      <td>190000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5002.671689</td>\n",
       "      <td>2696.349316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3169.400599</td>\n",
       "      <td>1944.910851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2244.000000</td>\n",
       "      <td>1014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4727.000000</td>\n",
       "      <td>2343.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7599.000000</td>\n",
       "      <td>4156.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11356.000000</td>\n",
       "      <td>7169.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userIDX        bookIDX\n",
       "count  190000.000000  190000.000000\n",
       "mean     5002.671689    2696.349316\n",
       "std      3169.400599    1944.910851\n",
       "min         0.000000       0.000000\n",
       "25%      2244.000000    1014.000000\n",
       "50%      4727.000000    2343.000000\n",
       "75%      7599.000000    4156.000000\n",
       "max     11356.000000    7169.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190000.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.2149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating\n",
       "count  190000.0000\n",
       "mean        3.8960\n",
       "std         1.2149\n",
       "min         0.0000\n",
       "25%         3.0000\n",
       "50%         4.0000\n",
       "75%         5.0000\n",
       "max         5.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4970.505400</td>\n",
       "      <td>2691.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3166.930712</td>\n",
       "      <td>1935.087554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2233.500000</td>\n",
       "      <td>1021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4685.500000</td>\n",
       "      <td>2353.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7559.250000</td>\n",
       "      <td>4149.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11350.000000</td>\n",
       "      <td>7165.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userIDX       bookIDX\n",
       "count  10000.000000  10000.000000\n",
       "mean    4970.505400   2691.034700\n",
       "std     3166.930712   1935.087554\n",
       "min        1.000000      0.000000\n",
       "25%     2233.500000   1021.000000\n",
       "50%     4685.500000   2353.500000\n",
       "75%     7559.250000   4149.000000\n",
       "max    11350.000000   7165.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.201974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  10000.000000\n",
       "mean       3.911100\n",
       "std        1.201974\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split \n",
    "\n",
    "split = 190000\n",
    "\n",
    "train_x = shuffled_data.loc[:split-1, 'userIDX':'bookIDX']\n",
    "train_y = shuffled_data.loc[:split-1, 'rating':'rating']\n",
    "test_x = shuffled_data.loc[split:, 'userIDX':'bookIDX']\n",
    "test_y = shuffled_data.loc[split:, 'rating':'rating']\n",
    "\n",
    "display(train_x.describe())\n",
    "display(train_y.describe())\n",
    "display(test_x.describe())\n",
    "display(test_y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-3\n",
    "k = 1\n",
    "# New parameter for regularizing bias\n",
    "c_bias = 1e-5\n",
    "c_vector = 1e-5\n",
    "batchsize = 1024\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] Iteration[0] Training Loss: 18685.96\n",
      "Epoch[0] Validation Loss: 18656.13 \n",
      "Epoch[0] Iteration[100] Training Loss: 15946.17\n",
      "Epoch[0] Validation Loss: 15921.08 \n",
      "Epoch[10] Iteration[0] Training Loss: 1026.40\n",
      "Epoch[10] Validation Loss: 1025.01 \n",
      "Epoch[10] Iteration[100] Training Loss: 871.64\n",
      "Epoch[10] Validation Loss: 870.23 \n",
      "Epoch[20] Iteration[0] Training Loss: 37.45\n",
      "Epoch[20] Validation Loss: 37.42 \n",
      "Epoch[20] Iteration[100] Training Loss: 31.10\n",
      "Epoch[20] Validation Loss: 30.98 \n",
      "Epoch[30] Iteration[0] Training Loss: 2.43\n",
      "Epoch[30] Validation Loss: 2.44 \n",
      "Epoch[30] Iteration[100] Training Loss: 2.27\n",
      "Epoch[30] Validation Loss: 2.28 \n",
      "Epoch[40] Iteration[0] Training Loss: 1.52\n",
      "Epoch[40] Validation Loss: 1.56 \n",
      "Epoch[40] Iteration[100] Training Loss: 1.52\n",
      "Epoch[40] Validation Loss: 1.55 \n",
      "Epoch[50] Iteration[0] Training Loss: 1.40\n",
      "Epoch[50] Validation Loss: 1.53 \n",
      "Epoch[50] Iteration[100] Training Loss: 1.43\n",
      "Epoch[50] Validation Loss: 1.53 \n",
      "Epoch[60] Iteration[0] Training Loss: 1.53\n",
      "Epoch[60] Validation Loss: 1.53 \n",
      "Epoch[60] Iteration[100] Training Loss: 1.40\n",
      "Epoch[60] Validation Loss: 1.53 \n",
      "Epoch[70] Iteration[0] Training Loss: 1.29\n",
      "Epoch[70] Validation Loss: 1.54 \n",
      "Epoch[70] Iteration[100] Training Loss: 1.35\n",
      "Epoch[70] Validation Loss: 1.54 \n",
      "Epoch[80] Iteration[0] Training Loss: 1.29\n",
      "Epoch[80] Validation Loss: 1.55 \n",
      "Epoch[80] Iteration[100] Training Loss: 1.40\n",
      "Epoch[80] Validation Loss: 1.55 \n",
      "Epoch[90] Iteration[0] Training Loss: 1.53\n",
      "Epoch[90] Validation Loss: 1.56 \n",
      "Epoch[90] Iteration[100] Training Loss: 1.31\n",
      "Epoch[90] Validation Loss: 1.56 \n",
      "Epoch[100] Iteration[0] Training Loss: 1.26\n",
      "Epoch[100] Validation Loss: 1.57 \n",
      "Epoch[100] Iteration[100] Training Loss: 1.37\n",
      "Epoch[100] Validation Loss: 1.57 \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# This code utilizes ignite engine's create_supervised_trainer()\n",
    "# But we need something more basic\n",
    "\n",
    "model = MF(n_user, n_item, k=k, c_vector=c_vector)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def chunks(X, Y, size):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    starts = list(range(0, len(X), size))\n",
    "    shuffle(starts)\n",
    "    for i in starts:\n",
    "        yield (X[i:i + size], Y[i:i + size])\n",
    "        \n",
    "batch_size = 1024\n",
    "losses = []\n",
    "for epoch in range(100+1):\n",
    "    \n",
    "    i = 0\n",
    "    for feature, target in chunks(np.array(train_x), np.array(train_y), batch_size):\n",
    "        # This zeros the gradients on every parameter. \n",
    "        # This is easy to miss and hard to troubleshoot.\n",
    "        optimizer.zero_grad()\n",
    "        # Convert \n",
    "        feature = Variable(torch.from_numpy(feature))\n",
    "        target = Variable(torch.from_numpy(target).type(torch.FloatTensor))\n",
    "        \n",
    "        if cuda:\n",
    "            feature = feature.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        # Compute a prediction for these features\n",
    "        prediction = model.forward(feature)\n",
    "        # Compute a loss given what the true target outcome was\n",
    "        loss = model.loss(prediction, target)\n",
    "        # break\n",
    "        # Backpropagate: compute the direction / gradient every model parameter\n",
    "        # defined in your __init__ should move in in order to minimize this loss\n",
    "        # However, we're not actually changing these parameters, we're just storing\n",
    "        # how they should change.\n",
    "\n",
    "        loss.backward()\n",
    "        # Now take a step & update the model parameters. The optimizer uses the gradient at \n",
    "        # defined on every parameter in our model and nudges it in that direction.\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0 and epoch%10 == 0:\n",
    "            print(\"Epoch[{}] Iteration[{}] Training Loss: {:.2f}\".format(epoch, i, loss.data))\n",
    "\n",
    "        # Record the loss per example\n",
    "        losses.append(loss.cpu().data.numpy() / len(feature))\n",
    "        \n",
    "        if i%100 == 0 and epoch%10 == 0:\n",
    "            feature = torch.from_numpy(np.array(test_x))\n",
    "            target = torch.from_numpy(np.array(test_y)).type(torch.FloatTensor)\n",
    "            \n",
    "            if cuda:\n",
    "                feature = feature.cuda()\n",
    "                target = target.cuda()\n",
    "\n",
    "            prediction = model.forward(feature)\n",
    "            loss = model.loss(prediction, target)\n",
    "            print(\"Epoch[{}] Validation Loss: {:.2f} \".format(epoch, loss.data))\n",
    "\n",
    "        i += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.LongTensor'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.4286665e-04],\n",
       "       [ 9.0880181e-05],\n",
       "       [ 1.2562422e-04],\n",
       "       ...,\n",
       "       [-3.9689295e-04],\n",
       "       [-5.0739350e-06],\n",
       "       [ 8.3241666e-06]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu().bias_user.weight.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.from_numpy(np.array(test_x))\n",
    "target = torch.from_numpy(np.array(test_y)).type(torch.FloatTensor)\n",
    "\n",
    "prediction = model.forward(feature)\n",
    "loss = model.loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7856)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 Kaggle Submission \n",
    "### Lambda=1.2e-5,  MSE=1.143, User_Name='Luke Liem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
