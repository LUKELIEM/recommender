{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "  f = open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')\n",
    "    \n",
    "def calc_model_stats(pred,label):\n",
    "    \n",
    "    TP,FP,TN,FN = calc_metrics(pred,label)\n",
    "\n",
    "    # print(\"Stats\")\n",
    "    # print(TP,FP,TN,FN)\n",
    "\n",
    "    # print(\"Predict N: {} ({}%)\".format(TN+FN,(TN+FN)/(TP+TN+FP+FN)))\n",
    "    # print(\"Predict P: {} ({}%)\".format(TP+FP,(TP+FP)/(TP+TN+FP+FN)))\n",
    "\n",
    "    accuracy, TPR, TNR, BER = calc_error_rates(TP, FP, TN, FN)\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    # print(\"TPR: {}\".format(TPR))\n",
    "    # print(\"TNR: {}\".format(TNR))\n",
    "    # print(\"BER: {}\".format(BER))\n",
    "    \n",
    "    return\n",
    " \n",
    "def calc_metrics(predictions, labels):\n",
    "    # Calculate True positives, false positives, etc.\n",
    "\n",
    "    TP_ = numpy.logical_and(predictions, labels)\n",
    "    FP_ = numpy.logical_and(predictions, numpy.logical_not(labels))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(labels))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(predictions), labels)\n",
    "\n",
    "    TP=sum(TP_)\n",
    "    FP=sum(FP_)\n",
    "    TN=sum(TN_)\n",
    "    FN=sum(FN_)\n",
    "    \n",
    "    return TP,FP,TN,FN\n",
    "\n",
    "def calc_error_rates(TP, FP, TN, FN):\n",
    "    # Calculate accuracy, TPR, TNR and BER\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1.0 - (TPR+TNR)/2\n",
    "    \n",
    "    return accuracy, TPR, TNR, BER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Dataset into Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 190001 9999\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for user,book,rating in readCSV(\"assignment1/train_Interactions.csv\"):\n",
    "  dataset.append([user,book,rating,1])\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "X = [values[0:3] for values in dataset]\n",
    "y = [values[-1] for values in dataset]\n",
    "\n",
    "N = len(dataset)\n",
    "Ntrain = 190001\n",
    "\n",
    "Xtrain = X[:Ntrain]\n",
    "Xvalid = X[Ntrain:]\n",
    "\n",
    "ytrain = y[:Ntrain]\n",
    "yvalid = y[Ntrain:]\n",
    "\n",
    "print(N, len(ytrain),len(yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of books: 7170\n",
      "Total num of readers: 11357\n",
      "Total num of reads: 200000\n"
     ]
    }
   ],
   "source": [
    "bookCount = defaultdict(int)\n",
    "readerCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book,_ in readCSV(\"assignment1/train_Interactions.csv\"):\n",
    "  bookCount[book] += 1\n",
    "  readerCount[user] += 1\n",
    "  totalRead += 1\n",
    "\n",
    "print(\"Total num of books: {}\".format(len(bookCount)))    \n",
    "print(\"Total num of readers: {}\".format(len(readerCount))) \n",
    "print(\"Total num of reads: {}\".format(totalRead))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lists and sets for Similarity Calculations\n",
    "\n",
    "#### Jaccard Similarity between Books\n",
    "\n",
    "Jsim(i,j) = Intersection(U_i, U_j)/ Union(U_i, U_j)  \n",
    "\n",
    "where U_i, U_j are set of readers who have read book i and book j  \n",
    "\n",
    "#### Pearson Similarity between Books\n",
    "\n",
    "\n",
    "Psim(i,j) = Sum_Product_crij((R_u_i-AR_u), (R_u_j-AR_u))/ SqRt(Sum_crij(Sq(R_u_i-AR_u)))SqRt(Sum_crij(Sq(R_u_j-AR_u)))  \n",
    "\n",
    "where \n",
    "* crij - the set of readers who have read both book i and j  \n",
    "* R_u_i = Rating that reader u gives book i  \n",
    "* AR_u = Average rating given by reader u  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "user_Books_full = defaultdict(set)  # Set of (user, books_read)\n",
    "user_Books_Ratings_full = defaultdict(set)  # Set of (user, set(book_read, rating))\n",
    "book_Readers_full = defaultdict(set)  # Set of (book, readers)\n",
    "book_ids=[]\n",
    "reader_ids=[]\n",
    "\n",
    "i=0\n",
    "for user,book,rating in X:\n",
    "  if i % 1000 == 0:\n",
    "      print ('.', end='')\n",
    "  i += 1\n",
    "\n",
    "  user_Books_full[user].add(book)\n",
    "  user_Books_Ratings_full[user].add((book,rating))\n",
    "  book_Readers_full[book].add(user)\n",
    "  if book not in book_ids:\n",
    "        book_ids.append(book)\n",
    "  if user not in reader_ids:\n",
    "        reader_ids.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11357 7170\n"
     ]
    }
   ],
   "source": [
    "print(len(reader_ids), len(book_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_Books_train = defaultdict(set)\n",
    "user_Books_Ratings_train = defaultdict(set)\n",
    "book_Readers_train = defaultdict(set)\n",
    "book_Ratings_train = defaultdict(set)\n",
    "\n",
    "for user,book,rating in Xtrain:\n",
    "  user_Books_train[user].add(book)\n",
    "  user_Books_Ratings_train[user].add((book,rating))\n",
    "  book_Readers_train[book].add(user)\n",
    "  book_Ratings_train[book].add(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11357, 11357, 7170, 7170)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_Books_train),len(user_Books_Ratings_train),len(book_Readers_train),len(book_Ratings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Composition of Xtrain\n",
    "\n",
    "Some of the readers have very few datapoints. We need to augment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ebd90a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uCount = defaultdict(int)\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book,rating in Xtrain:\n",
    "  uCount[user] += 1\n",
    "\n",
    "counts = []\n",
    "for id, count in  uCount.items():\n",
    "    counts.append(count)\n",
    "\n",
    "data = numpy.array(counts).T\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data, bins=100)\n",
    "plt.show    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a validation dataset of alternating read and unread books per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unread_book(user, read_books):\n",
    "    # Find a random unread book for a specific user\n",
    "    \n",
    "    book = random.choice(book_ids)  # pick a book from full library\n",
    "    while book in read_books:\n",
    "        book = random.choice(book_ids)\n",
    "    return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid_full = []\n",
    "yvalid_full = []\n",
    "\n",
    "for value in zip(Xvalid,yvalid):\n",
    "    x,read = value\n",
    "    user = x[0]\n",
    "    book = x[1]\n",
    "    Xvalid_full.append([user, book])\n",
    "    yvalid_full.append(read)\n",
    "    \n",
    "    book = unread_book(user, user_Books_full[user])\n",
    "    Xvalid_full.append([user, book])\n",
    "    yvalid_full.append(0)\n",
    "    \n",
    "Xtrain_full = []\n",
    "ytrain_full = []\n",
    "\n",
    "for value in zip(Xtrain,ytrain):\n",
    "    x,read = value\n",
    "    user = x[0]\n",
    "    book = x[1]\n",
    "    Xtrain_full.append([user, book])\n",
    "    ytrain_full.append(read)\n",
    "    \n",
    "    book = unread_book(user, user_Books_full[user])\n",
    "    Xtrain_full.append([user, book])\n",
    "    ytrain_full.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5eef1a3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uCount = defaultdict(int)\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book in Xtrain_full:\n",
    "  uCount[user] += 1\n",
    "\n",
    "counts = []\n",
    "for id, count in  uCount.items():\n",
    "    counts.append(count)\n",
    "\n",
    "data = numpy.array(counts).T\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data, bins=100)\n",
    "plt.show   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_Jsims_train = []\n",
    "U_Psims_train = []\n",
    "B_Jsims_train = []\n",
    "B_Psims_train = []\n",
    "\n",
    "U_Jsims_valid = []\n",
    "U_Psims_valid = []\n",
    "B_Jsims_valid = []\n",
    "B_Psims_valid = []\n",
    "\n",
    "for u,b in Xtrain_full:\n",
    "    U_Jsims_train.append(list_pad(jsim_mostSimilar_users(b,u),8))\n",
    "    U_Psims_train.append(list_pad(psim_mostSimilar_users(b,u),8))    \n",
    "    B_Jsims_train.append(list_pad(jsim_mostSimilar_items(u,b),8))\n",
    "    B_Psims_train.append(list_pad(psim_mostSimilar_items(u,b),8))\n",
    "\n",
    "for u,b in Xvalid_full:\n",
    "    U_Jsims_valid.append(list_pad(jsim_mostSimilar_users(b,u),8))\n",
    "    U_Psims_valid.append(list_pad(psim_mostSimilar_users(b,u),8))    \n",
    "    B_Jsims_valid.append(list_pad(jsim_mostSimilar_items(u,b),8)) \n",
    "    B_Psims_valid.append(list_pad(psim_mostSimilar_items(u,b),8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_pad(l, n):\n",
    "    # if len(l) > n, the method truncates the list l to length n \n",
    "    # if n > len(l), the method pads list l with zero up to length n \n",
    "    return l[:n] + [0]*(n-len(l))\n",
    "\n",
    "def find_rating(reader,book):\n",
    "    rating = 0\n",
    "    for b, rating in user_Books_Ratings_train[reader]:\n",
    "        if book == b:\n",
    "            return int(rating)\n",
    "    return int(rating)\n",
    "\n",
    "def average_rating(reader):\n",
    "    ratings = []\n",
    "    for _, rating in user_Books_Ratings_train[reader]:\n",
    "        ratings.append(int(rating))\n",
    "    \n",
    "    if len(ratings) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return sum(ratings)/len(ratings)\n",
    "\n",
    "\"\"\"\n",
    "Jaccard Similarity\n",
    "\"\"\"\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "\"\"\"\n",
    "When evaluating whether a reader will read a certain book, we can approach it in two ways:\n",
    "(1) Is the book similar to all the other books the reader has read?\n",
    "(2) Is the reader similar to all the other readers who have read the same book?\n",
    "\"\"\"\n",
    "\n",
    "def items_jsim(book1, book2):\n",
    "    # generate readers set for the 2 books based on train dataset\n",
    "    s1 = book_Readers_train[book1]\n",
    "    s2 = book_Readers_train[book2]\n",
    "    return Jaccard(s1, s2)\n",
    "\n",
    "def users_jsim(reader1, reader2):\n",
    "    # generate Books set for the 2 readers based on train dataset\n",
    "    s1 = user_Books_train[reader1]\n",
    "    s2 = user_Books_train[reader2]\n",
    "    return Jaccard(s1, s2)\n",
    "\n",
    "def jsim_mostSimilar_items(r,b):\n",
    "    # Find books read by reader r that are most similar to book b\n",
    "    # and return Jaccard(b, book) in descending order\n",
    "    jsims = []\n",
    "    \n",
    "    # Go through the books read by reader r\n",
    "    for other_book in user_Books_train[r]:\n",
    "        if b == other_book: \n",
    "           continue   # skip if the book is b\n",
    "        jsim = items_jsim(b, other_book)\n",
    "        jsims.append(jsim)\n",
    "       \n",
    "    jsims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return jsims  \n",
    "\n",
    "def jsim_mostSimilar_users(b,r):\n",
    "    # Find readers who read book b that are most similar to the reader r\n",
    "    # and return Jaccard(r, reader) in descending order\n",
    "    jsims = []\n",
    "    \n",
    "    # Go through the readers who read book b\n",
    "    for reader in book_Readers_train[b]:\n",
    "        if r == reader: \n",
    "           continue   # skip if the reader is r\n",
    "        jsim = users_jsim(r, reader)\n",
    "        jsims.append(jsim)\n",
    "       \n",
    "    jsims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return jsims  \n",
    "\n",
    "\n",
    "def jaccard_predict(user, book, threshold):\n",
    "    \"\"\"\n",
    "    user_jsims = jsim_mostSimilar_users(book,user)\n",
    "    if len(user_jsims) is 0:\n",
    "        max_jsim = 0\n",
    "    else:\n",
    "        max_jsim = user_jsims[0]\n",
    "    \"\"\"    \n",
    "    book_jsims = jsim_mostSimilar_items(user,book)\n",
    "    if len(book_jsims) is 0:\n",
    "        max_jsim = 0\n",
    "    else:\n",
    "        max_jsim = book_jsims[0]\n",
    "        \n",
    "    if max_jsim > threshold:\n",
    "        predict = True\n",
    "    else:\n",
    "        predict = False\n",
    "    return predict, max_jsim\n",
    "\n",
    "\"\"\"\n",
    "Pearson Similarity\n",
    "\n",
    "When evaluating whether a reader will read a certain book, we can approach it in two ways:\n",
    "(1) Is the book similar to all the other books the reader has read?\n",
    "(2) Is the reader similar to all the other readers who have read the same book?\n",
    "\"\"\"\n",
    "\n",
    "def users_Pearson(r1,r2):\n",
    "    \n",
    "    books_r1 = set([])\n",
    "    ratings_r1 = []\n",
    "    \n",
    "    for book,rating in user_Books_Ratings_train[r1]:\n",
    "        # print (book,rating)\n",
    "        books_r1.add(book)\n",
    "        ratings_r1.append(int(rating))\n",
    "        \n",
    "    if len(ratings_r1) == 0:\n",
    "        avRating_r1 = 0\n",
    "    else:\n",
    "        avRating_r1 = sum(ratings_r1)/len(ratings_r1)\n",
    "        \n",
    "    # print(books_r1)\n",
    "    # print(avRating_r1)\n",
    "    \n",
    "    books_r2 = set([])\n",
    "    ratings_r2 = []\n",
    "    \n",
    "    for book,rating in user_Books_Ratings_train[r2]:\n",
    "        # print (book,rating)\n",
    "        books_r2.add(book)\n",
    "        ratings_r2.append(int(rating))\n",
    "        \n",
    "    if len(ratings_r2) == 0:\n",
    "        avRating_r2 = 0\n",
    "    else:\n",
    "        avRating_r2 = sum(ratings_r2)/len(ratings_r2)  \n",
    "    \n",
    "    # print(books_r2)\n",
    "    # print(avRating_r2)\n",
    "        \n",
    "    common = books_r1.intersection(books_r2)\n",
    "    if len(common) == 0:  # return psim=0 if no common book\n",
    "        return 0\n",
    "        \n",
    "    # print(common)\n",
    "    \n",
    "    sumProducts = []\n",
    "    sumSq_R1 = []\n",
    "    sumSq_R2 = []\n",
    "    for book in common:\n",
    "        pR_r1 = find_rating(r1,book) - avRating_r1\n",
    "        pR_r2 = find_rating(r2,book) - avRating_r2\n",
    "        # print(find_rating(r1,book), pR_r1)\n",
    "        # print(find_rating(r2,book), pR_r2)\n",
    "        sumProducts.append(pR_r1*pR_r2)\n",
    "        sumSq_R1.append(pR_r1**2)\n",
    "        sumSq_R2.append(pR_r2**2)\n",
    "        \n",
    "    if sum(sumSq_R1) == 0 or sum(sumSq_R2) == 0:\n",
    "        return 0\n",
    "        \n",
    "    # print(sumProducts)\n",
    "    # print(sumSq_R1)\n",
    "    # print(sumSq_R2)\n",
    "    \n",
    "    psim = sum(sumProducts)/math.sqrt(sum(sumSq_R1)*sum(sumSq_R2))\n",
    "    return psim\n",
    "\n",
    "def items_Pearson(b1,b2):\n",
    "    \n",
    "    # Create a set of common readers for book b1 and b2\n",
    "    readers_b1 = set([])\n",
    "    for reader in book_Readers_train[b1]:\n",
    "        readers_b1.add(reader)\n",
    "        \n",
    "    readers_b2 = set([])\n",
    "    for reader in book_Readers_train[b2]:\n",
    "        readers_b2.add(reader)\n",
    "        \n",
    "    common = readers_b1.intersection(readers_b2)\n",
    "    if len(common) == 0:  # return psim=0 if no common readers\n",
    "        return 0\n",
    "        \n",
    "    # print(common)\n",
    "    \n",
    "    sumProducts = []\n",
    "    sumSq_R1 = []\n",
    "    sumSq_R2 = []\n",
    "    for reader in common:\n",
    "        avRating = average_rating(reader)\n",
    "        # print(avRating)\n",
    "        pR_b1 = find_rating(reader,b1) - avRating\n",
    "        pR_b2 = find_rating(reader,b2) - avRating\n",
    "        # print(find_rating(reader,b1), pR_b1)\n",
    "        # print(find_rating(reader,b2), pR_b2)\n",
    "        sumProducts.append(pR_b1*pR_b2)\n",
    "        sumSq_R1.append(pR_b1**2)\n",
    "        sumSq_R2.append(pR_b2**2)\n",
    "        \n",
    "    if sum(sumSq_R1) == 0 or sum(sumSq_R2) == 0:\n",
    "        return 0\n",
    "        \n",
    "    # print(sumProducts)\n",
    "    # print(sumSq_R1)\n",
    "    # print(sumSq_R2)\n",
    "    \n",
    "    psim = sum(sumProducts)/math.sqrt(sum(sumSq_R1)*sum(sumSq_R2))\n",
    "    return psim\n",
    "\n",
    "def psim_mostSimilar_users(b,r):\n",
    "    # Find readers who read book b that are most similar to the reader r\n",
    "    # and return Pearson(r, reader) in descending order\n",
    "    psims = []\n",
    "    \n",
    "    # Go through the readers who read book b\n",
    "    for reader in book_Readers_train[b]:\n",
    "        if r == reader: \n",
    "           continue   # skip if the reader is r\n",
    "        psim = users_Pearson(r, reader)\n",
    "        # print (reader, psim)\n",
    "        psims.append(psim)\n",
    "       \n",
    "    psims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return psims  \n",
    "\n",
    "def psim_mostSimilar_items(r,b):\n",
    "    # Find books read by reader r that are most similar to the book b\n",
    "    # and return Pearson(b, book) in descending order\n",
    "    psims = []\n",
    "    \n",
    "    # Go through the books read by reader r \n",
    "    for book in user_Books_train[r]:\n",
    "        if book == b: \n",
    "           continue   # skip if the book is b\n",
    "        psim = items_Pearson(b, book)\n",
    "        # print (book, psim)\n",
    "        psims.append(psim)\n",
    "       \n",
    "    psims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return psims  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.043478260869565216,\n",
       " 0.03508771929824561,\n",
       " 0.03333333333333333,\n",
       " 0.03333333333333333,\n",
       " 0.029411764705882353,\n",
       " 0.02857142857142857,\n",
       " 0.027777777777777776,\n",
       " 0.02631578947368421,\n",
       " 0.023255813953488372,\n",
       " 0.021739130434782608,\n",
       " 0.017543859649122806,\n",
       " 0.012048192771084338,\n",
       " 0.011627906976744186,\n",
       " 0.011494252873563218,\n",
       " 0.00980392156862745,\n",
       " 0.007751937984496124]"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsim_mostSimilar_items('u80908575', 'b72504285')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04,\n",
       " 0.038461538461538464,\n",
       " 0.038461538461538464,\n",
       " 0.037037037037037035,\n",
       " 0.03571428571428571,\n",
       " 0.034482758620689655,\n",
       " 0.034482758620689655,\n",
       " 0.03333333333333333,\n",
       " 0.03225806451612903,\n",
       " 0.03225806451612903,\n",
       " 0.027777777777777776,\n",
       " 0.02564102564102564,\n",
       " 0.025,\n",
       " 0.023255813953488372,\n",
       " 0.02,\n",
       " 0.015625]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsim_mostSimilar_users('b72504285','u80908575')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625965372547114\n"
     ]
    }
   ],
   "source": [
    "psim = users_Pearson('u39338306', 'u26190516')\n",
    "\n",
    "print (psim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.2583995305802754,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " -0.9999999999999999,\n",
       " -1.0,\n",
       " -1.0]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psim_mostSimilar_users('b72504285','u26190516')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9143933864809832\n"
     ]
    }
   ],
   "source": [
    "psim = items_Pearson('b25543219', 'b21517939')\n",
    "\n",
    "print (psim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000000000002, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -0.6528305817830342, -0.9607324330163716, -1.0, -1.0]\n",
      "-0.09491547145878858\n"
     ]
    }
   ],
   "source": [
    "psims = psim_mostSimilar_items('u77362867','b98180843')\n",
    "\n",
    "print(psims)\n",
    "print(sum(psims)/len(psims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Logistic Regression Model - Popularity Only\n",
    "\n",
    "Start simple:\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [popularity], popularity= (times a book is read)/(total num of reads)\n",
    "\n",
    "Accuracy = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.000315], [1, 0.000115], [1, 0.000395], [1, 0.00014], [1, 0.00015], [1, 0.00031], [1, 7.5e-05], [1, 9e-05], [1, 0.00016], [1, 6.5e-05]]\n"
     ]
    }
   ],
   "source": [
    "X_train = [[1,bookCount[x]/totalRead] for _,x in Xtrain_full]\n",
    "y_train = ytrain_full\n",
    "\n",
    "X_valid = [[1,bookCount[x]/totalRead] for _,x in Xvalid_full]\n",
    "y_valid = yvalid_full\n",
    "\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.000375], [1, 3.5e-05], [1, 8e-05], [1, 0.000755], [1, 7e-05], [1, 3.5e-05], [1, 0.00013], [1, 0.000115], [1, 0.00014], [1, 0.000195]]\n"
     ]
    }
   ],
   "source": [
    "# X_train = [[1,bookCount[b]/totalRead,readerCount[u]/totalRead] for u,b in Xtrain_full]\n",
    "X_train = [[1,bookCount[b]/totalRead] for u,b in Xtrain_full]\n",
    "\n",
    "y_train = ytrain_full\n",
    "\n",
    "# X_valid = [[1,bookCount[b]/totalRead,readerCount[u]/totalRead] for u,b in Xvalid_full]\n",
    "X_valid = [[1,bookCount[b]/totalRead] for u,b in Xvalid_full]\n",
    "y_valid = yvalid_full\n",
    "\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.5\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 8e-06\n",
      "Training:\n",
      "Accuracy: 0.6589939000321051\n",
      "Validation:\n",
      "Accuracy: 0.6557655765576558\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.658172851721833\n",
      "Validation:\n",
      "Accuracy: 0.6548154815481548\n",
      "\n",
      "\n",
      "Regularization = 1.2e-05\n",
      "Training:\n",
      "Accuracy: 0.6606991542149778\n",
      "Validation:\n",
      "Accuracy: 0.6578157815781578\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.6473071194362134\n",
      "Validation:\n",
      "Accuracy: 0.6468646864686468\n",
      "\n",
      "\n",
      "Regularization = 0.001\n",
      "Training:\n",
      "Accuracy: 0.6461229151425519\n",
      "Validation:\n",
      "Accuracy: 0.6449144914491449\n",
      "\n",
      "\n",
      "Regularization = 0.01\n",
      "Training:\n",
      "Accuracy: 0.6461229151425519\n",
      "Validation:\n",
      "Accuracy: 0.6449144914491449\n",
      "\n",
      "\n",
      "Regularization = 0.1\n",
      "Training:\n",
      "Accuracy: 0.6461229151425519\n",
      "Validation:\n",
      "Accuracy: 0.6449144914491449\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 8e-6, 1e-5, 1.2e-5,1e-4, 1e-3, 0.01, 0.1]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Logistic Regression Model - Popularity + Books' Jaccard Similarity\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [book_popularity, book_similarity_1,book_similarity_2] \n",
    "\n",
    "book_popularity= (times a book is read)/(total num of reads)  \n",
    "book_similarity_1 = Jaccard similarity of the book and the most similar book read by the reader  \n",
    "book_similarity_2 = Jaccard similarity of the book and 2nd most similar book read by the reader  \n",
    "and so on ...  \n",
    "\n",
    "Accuracy = 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "\"\"\"\n",
    "for u,b in Xtrain_full:\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),4)\n",
    "    X_train.append([1, bookCount[b]/totalRead, user_jsims[0]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for u,b in Xvalid_full:\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),4)\n",
    "    X_valid.append([1, bookCount[b]/totalRead, user_jsims[0]])\n",
    "y_valid = yvalid_full\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, user_jsims[0]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, user_jsims[0]])\n",
    "y_valid = yvalid_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.6227519855158657\n",
      "Validation:\n",
      "Accuracy: 0.5894089408940895\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7285777443276614\n",
      "Validation:\n",
      "Accuracy: 0.6333633363336334\n",
      "\n",
      "\n",
      "Regularization = 6e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7577196962121252\n",
      "Validation:\n",
      "Accuracy: 0.6365636563656366\n",
      "\n",
      "\n",
      "Regularization = 7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7824485134288767\n",
      "Validation:\n",
      "Accuracy: 0.6407640764076408\n",
      "\n",
      "\n",
      "Regularization = 8e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7998800006315756\n",
      "Validation:\n",
      "Accuracy: 0.6432143214321432\n",
      "\n",
      "\n",
      "Regularization = 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.809208898900532\n",
      "Validation:\n",
      "Accuracy: 0.6422642264226422\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8181193783190615\n",
      "Validation:\n",
      "Accuracy: 0.6402640264026402\n",
      "\n",
      "\n",
      "Regularization = 1.1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8270245946073969\n",
      "Validation:\n",
      "Accuracy: 0.6408140814081408\n",
      "\n",
      "\n",
      "Regularization = 1.2e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8352798143167668\n",
      "Validation:\n",
      "Accuracy: 0.6385638563856386\n",
      "\n",
      "\n",
      "Regularization = 1.3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8436508228904058\n",
      "Validation:\n",
      "Accuracy: 0.6375137513751375\n",
      "\n",
      "\n",
      "Regularization = 1.4e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8509007847327119\n",
      "Validation:\n",
      "Accuracy: 0.6347134713471347\n",
      "\n",
      "\n",
      "Regularization = 1.5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8509271003836822\n",
      "Validation:\n",
      "Accuracy: 0.6340634063406341\n",
      "\n",
      "\n",
      "Regularization = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8731269835421919\n",
      "Validation:\n",
      "Accuracy: 0.6006600660066007\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 5e-6, 6e-6, 7e-6, 8e-6, 9e-6, 1e-5, 1.1e-5, 1.2e-5, 1.3e-5, 1.4e-5, 1.5e-5, 5e-5]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Logistic Regression Model - Popularity+ Books' JSim + Users' JSim\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [book_popularity, user_similarity_1,user_similarity_2, book_similarity_1,book_similarity_2] \n",
    "\n",
    "book_popularity= (times a book is read)/(total num of reads)  \n",
    "user_similarity_1 = Jaccard similarity of the user and the most similar user who read the book  \n",
    "user_similarity_2 = Jaccard similarity of the user and the 2nd most similar user who read the book  \n",
    "book_similarity_1 = Jaccard similarity of the book and the most similar book read by the reader  \n",
    "book_similarity_2 = Jaccard similarity of the book and 2nd most similar book read by the reader  \n",
    "\n",
    "and so on ...  \n",
    "\n",
    "Accuracy = 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\"\"\"\n",
    "for u,b in Xtrain_full:\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),4)\n",
    "    X_train.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for u,b in Xvalid_full:\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),4)\n",
    "    X_valid.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_valid = yvalid_full\n",
    "\"\"\"\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_valid = yvalid_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.6688201641043995\n",
      "Validation:\n",
      "Accuracy: 0.6154615461546155\n",
      "\n",
      "\n",
      "Regularization = 2e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7419382003252615\n",
      "Validation:\n",
      "Accuracy: 0.6486148614861487\n",
      "\n",
      "\n",
      "Regularization = 3e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.7864853342877143\n",
      "Validation:\n",
      "Accuracy: 0.6652665266526653\n",
      "\n",
      "\n",
      "Regularization = 4e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8167378066431229\n",
      "Validation:\n",
      "Accuracy: 0.6702670267026702\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8387850590260051\n",
      "Validation:\n",
      "Accuracy: 0.6718171817181718\n",
      "\n",
      "\n",
      "Regularization = 6e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8555770759101268\n",
      "Validation:\n",
      "Accuracy: 0.6725672567256725\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.8935847706064705\n",
      "Validation:\n",
      "Accuracy: 0.6669166916691669\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "Accuracy: 0.9189477950116052\n",
      "Validation:\n",
      "Accuracy: 0.61001100110011\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 2e-6, 3e-6, 4e-6, 5e-6, 6e-6, 1e-5, 1e-4]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_valid = yvalid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6157615761576157\n",
      "\n",
      "\n",
      "Regularization = 4e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6742674267426743\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.678067806780678\n",
      "\n",
      "\n",
      "Regularization = 6e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6757675767576757\n",
      "\n",
      "\n",
      "Regularization = 7e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6756675667566757\n",
      "\n",
      "\n",
      "Regularization = 8e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6732673267326733\n",
      "\n",
      "\n",
      "Regularization = 9e-06\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6706170617061706\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6684668466846685\n",
      "\n",
      "\n",
      "Regularization = 1.1e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6658165816581658\n",
      "\n",
      "\n",
      "Regularization = 1.2e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.662966296629663\n",
      "\n",
      "\n",
      "Regularization = 1.3e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6602660266026603\n",
      "\n",
      "\n",
      "Regularization = 1.4e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6567656765676567\n",
      "\n",
      "\n",
      "Regularization = 1.5e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6526652665266527\n",
      "\n",
      "\n",
      "Regularization = 5e-05\n",
      "Validation Error Stats\n",
      "Accuracy: 0.6147114711471147\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 4e-6, 5e-6, 6e-6, 7e-6, 8e-6, 9e-6, 1e-5, 1.1e-5, 1.2e-5, 1.3e-5, 1.4e-5, 1.5e-5, 5e-5]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    # print(\"Training Error Stats\")\n",
    "    # calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation Error Stats\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission, Accuracy=0.693, User_Name='Luke Liem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukeliem/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "users=[]\n",
    "books=[]\n",
    "X_test=[]\n",
    "\n",
    "model = linear_model.LogisticRegression(max_iter = 1000, C=5e-6, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = open(\"assignment1/predictions_Read.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Read.txt\"):\n",
    "\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    \n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    users.append(u)\n",
    "    books.append(b)\n",
    "    \n",
    "    # Predict using Jaccard similarity\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),8)\n",
    "    book_jsims = list_pad(jsim_mostSimilar_items(u,b),8)\n",
    "    X_test.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "for u,b,pred in zip(users,books,test_pred):\n",
    "        predictions.write(u + '-' + b + \",\" + str(pred) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Logistic Regression Model - Popularity+ Books' JSim + Users' JSim\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [book_popularity, user_Jsim_1,user_Jsim_2, book_Jsim_1,book_Jsim_2, user_Psim_1,user_Psim_2] \n",
    "\n",
    "book_popularity= (times a book is read)/(total num of reads)  \n",
    "user_Jsim_1 = Jaccard similarity of the user and the most similar user who read the book  \n",
    "user_Jsim_2 = Jaccard similarity of the user and the 2nd most similar user who read the book  \n",
    "book_Jsim_1 = Jaccard similarity of the book and the most similar book read by the reader  \n",
    "book_Jsim_2 = Jaccard similarity of the book and 2nd most similar book read by the reader \n",
    "user_Psim_1 = Pearson similarity of the user and the most similar user who read the book  \n",
    "user_Psim_2 = Pearson similarity of the user and the 2nd most similar user who read the book \n",
    "\n",
    "and so on ...  \n",
    "\n",
    "Accuracy = 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead,\n",
    "                     user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "#                    book_jsims[0] \\\n",
    "                     user_psims[0],user_psims[1],user_psims[2], \\\n",
    "                     book_psims[0],book_psims[1]  \\\n",
    "                   ])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead,\n",
    "                     user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4],\\\n",
    "#                    book_jsims[0] \\\n",
    "                     user_psims[0],user_psims[1],user_psims[2], \\\n",
    "                     book_psims[0],book_psims[1]  \\\n",
    "                   ])\n",
    "y_valid = yvalid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-08\n",
      "Training:\n",
      "Accuracy: 0.6551544465555444\n",
      "Validation:\n",
      "Accuracy: 0.6048104810481049\n",
      "\n",
      "\n",
      "Regularization = 1e-07\n",
      "Training:\n",
      "Accuracy: 0.6515702548933953\n",
      "Validation:\n",
      "Accuracy: 0.6037603760376038\n",
      "\n",
      "\n",
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.651028152483408\n",
      "Validation:\n",
      "Accuracy: 0.6040604060406041\n",
      "\n",
      "\n",
      "Regularization = 3e-06\n",
      "Training:\n",
      "Accuracy: 0.7832774564344398\n",
      "Validation:\n",
      "Accuracy: 0.6517151715171517\n",
      "\n",
      "\n",
      "Regularization = 4e-06\n",
      "Training:\n",
      "Accuracy: 0.7833590349524476\n",
      "Validation:\n",
      "Accuracy: 0.6517651765176518\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n",
      "Training:\n",
      "Accuracy: 0.7836353492876353\n",
      "Validation:\n",
      "Accuracy: 0.6513151315131513\n",
      "\n",
      "\n",
      "Regularization = 6e-06\n",
      "Training:\n",
      "Accuracy: 0.7927089857421803\n",
      "Validation:\n",
      "Accuracy: 0.6538653865386539\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.8226798806322072\n",
      "Validation:\n",
      "Accuracy: 0.6534153415341534\n",
      "\n",
      "\n",
      "Regularization = 5e-05\n",
      "Training:\n",
      "Accuracy: 0.8495297393171615\n",
      "Validation:\n",
      "Accuracy: 0.6507150715071507\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.8752427618802007\n",
      "Validation:\n",
      "Accuracy: 0.6395639563956396\n",
      "\n",
      "\n",
      "Regularization = 0.001\n",
      "Training:\n",
      "Accuracy: 0.8849427108278377\n",
      "Validation:\n",
      "Accuracy: 0.6343134313431343\n",
      "\n",
      "\n",
      "Regularization = 0.0015\n",
      "Training:\n",
      "Accuracy: 0.8882400618944111\n",
      "Validation:\n",
      "Accuracy: 0.6320632063206321\n",
      "\n",
      "\n",
      "Regularization = 0.002\n",
      "Training:\n",
      "Accuracy: 0.8896663701769991\n",
      "Validation:\n",
      "Accuracy: 0.6313131313131313\n",
      "\n",
      "\n",
      "Regularization = 0.0025\n",
      "Training:\n",
      "Accuracy: 0.8911426781964306\n",
      "Validation:\n",
      "Accuracy: 0.6307630763076307\n",
      "\n",
      "\n",
      "Regularization = 0.005\n",
      "Training:\n",
      "Accuracy: 0.8961400203156825\n",
      "Validation:\n",
      "Accuracy: 0.6296629662966297\n",
      "\n",
      "\n",
      "Regularization = 0.01\n",
      "Training:\n",
      "Accuracy: 0.9009952579196951\n",
      "Validation:\n",
      "Accuracy: 0.6303630363036303\n",
      "\n",
      "\n",
      "Regularization = 0.025\n",
      "Training:\n",
      "Accuracy: 0.9115583602191567\n",
      "Validation:\n",
      "Accuracy: 0.6321132113211321\n",
      "\n",
      "\n",
      "Regularization = 0.05\n",
      "Training:\n",
      "Accuracy: 0.9260845995547392\n",
      "Validation:\n",
      "Accuracy: 0.6314631463146315\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambs = [1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 5e-3, 0.01, 0.025, 0.05]\n",
    "# [1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "#                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "#                    book_jsims[0],book_jsims[1], \\\n",
    "#                   ])\n",
    "# Regularization = 5e-06; Accuracy: 0.682018201820182\n",
    "\n",
    "lambs = [1e-8, 1e-7, 1e-6, 3e-6, 4e-6,5e-6,6e-6, 1e-5, 5e-5, 1e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 5e-3, 0.01, 0.025, 0.05]\n",
    "\n",
    "for lamb in lambs:\n",
    "\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0],book_jsims[1], \\\n",
    "                   ])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0],book_jsims[1], \\\n",
    "                   ])\n",
    "y_valid = yvalid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-07\n",
      "Training:\n",
      "Accuracy: 0.6226677754327609\n",
      "Validation:\n",
      "Accuracy: 0.5894089408940895\n",
      "\n",
      "\n",
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.6663885979547476\n",
      "Validation:\n",
      "Accuracy: 0.6157615761576157\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n",
      "Training:\n",
      "Accuracy: 0.8464955447602908\n",
      "Validation:\n",
      "Accuracy: 0.678067806780678\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.9079715369919106\n",
      "Validation:\n",
      "Accuracy: 0.6684668466846685\n",
      "\n",
      "\n",
      "Regularization = 5e-05\n",
      "Training:\n",
      "Accuracy: 0.9579370634891395\n",
      "Validation:\n",
      "Accuracy: 0.6147114711471147\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.959202846300809\n",
      "Validation:\n",
      "Accuracy: 0.6031103110311031\n",
      "\n",
      "\n",
      "Regularization = 0.001\n",
      "Training:\n",
      "Accuracy: 0.9601107362592829\n",
      "Validation:\n",
      "Accuracy: 0.5906590659065907\n",
      "\n",
      "\n",
      "Regularization = 0.0015\n",
      "Training:\n",
      "Accuracy: 0.9612396776859069\n",
      "Validation:\n",
      "Accuracy: 0.5910591059105911\n",
      "\n",
      "\n",
      "Regularization = 0.002\n",
      "Training:\n",
      "Accuracy: 0.9623896716333072\n",
      "Validation:\n",
      "Accuracy: 0.5909090909090909\n",
      "\n",
      "\n",
      "Regularization = 0.0025\n",
      "Training:\n",
      "Accuracy: 0.9632791406361019\n",
      "Validation:\n",
      "Accuracy: 0.5910591059105911\n",
      "\n",
      "\n",
      "Regularization = 0.005\n",
      "Training:\n",
      "Accuracy: 0.9661633359824422\n",
      "Validation:\n",
      "Accuracy: 0.5918091809180918\n",
      "\n",
      "\n",
      "Regularization = 0.01\n",
      "Training:\n",
      "Accuracy: 0.969000163157036\n",
      "Validation:\n",
      "Accuracy: 0.5912091209120912\n",
      "\n",
      "\n",
      "Regularization = 0.025\n",
      "Training:\n",
      "Accuracy: 0.9726869858579692\n",
      "Validation:\n",
      "Accuracy: 0.5895589558955896\n",
      "\n",
      "\n",
      "Regularization = 0.05\n",
      "Training:\n",
      "Accuracy: 0.9752369724369871\n",
      "Validation:\n",
      "Accuracy: 0.5857585758575857\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambs = [1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 5e-3, 0.01, 0.025, 0.05]\n",
    "# [1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "#                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "#                    book_jsims[0],book_jsims[1], \\\n",
    "#                   ])\n",
    "# Regularization = 5e-06; Accuracy: 0.682018201820182\n",
    "\n",
    "lambs = [1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 5e-3, 0.01, 0.025, 0.05]\n",
    "\n",
    "for lamb in lambs:\n",
    "\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
