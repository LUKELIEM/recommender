{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "  f = open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')\n",
    "    \n",
    "def calc_model_stats(pred,label):\n",
    "    \n",
    "    TP,FP,TN,FN = calc_metrics(pred,label)\n",
    "\n",
    "    # print(\"Stats\")\n",
    "    # print(TP,FP,TN,FN)\n",
    "\n",
    "    # print(\"Predict N: {} ({}%)\".format(TN+FN,(TN+FN)/(TP+TN+FP+FN)))\n",
    "    # print(\"Predict P: {} ({}%)\".format(TP+FP,(TP+FP)/(TP+TN+FP+FN)))\n",
    "\n",
    "    accuracy, TPR, TNR, BER = calc_error_rates(TP, FP, TN, FN)\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    # print(\"TPR: {}\".format(TPR))\n",
    "    # print(\"TNR: {}\".format(TNR))\n",
    "    # print(\"BER: {}\".format(BER))\n",
    "    \n",
    "    return\n",
    " \n",
    "def calc_metrics(predictions, labels):\n",
    "    # Calculate True positives, false positives, etc.\n",
    "\n",
    "    TP_ = numpy.logical_and(predictions, labels)\n",
    "    FP_ = numpy.logical_and(predictions, numpy.logical_not(labels))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(labels))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(predictions), labels)\n",
    "\n",
    "    TP=sum(TP_)\n",
    "    FP=sum(FP_)\n",
    "    TN=sum(TN_)\n",
    "    FN=sum(FN_)\n",
    "    \n",
    "    return TP,FP,TN,FN\n",
    "\n",
    "def calc_error_rates(TP, FP, TN, FN):\n",
    "    # Calculate accuracy, TPR, TNR and BER\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1.0 - (TPR+TNR)/2\n",
    "    \n",
    "    return accuracy, TPR, TNR, BER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Dataset into Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 190001 9999\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for user,book,rating in readCSV(\"assignment1/train_Interactions.csv\"):\n",
    "  dataset.append([user,book,rating,1])\n",
    "\n",
    "random.shuffle(dataset)\n",
    "\n",
    "X = [values[0:3] for values in dataset]\n",
    "y = [values[-1] for values in dataset]\n",
    "\n",
    "N = len(dataset)\n",
    "Ntrain = 190001\n",
    "\n",
    "Xtrain = X[:Ntrain]\n",
    "Xvalid = X[Ntrain:]\n",
    "\n",
    "ytrain = y[:Ntrain]\n",
    "yvalid = y[Ntrain:]\n",
    "\n",
    "print(N, len(ytrain),len(yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total num of books: 7170\n",
      "Total num of readers: 11357\n",
      "Total num of reads: 200000\n"
     ]
    }
   ],
   "source": [
    "bookCount = defaultdict(int)\n",
    "readerCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book,_ in readCSV(\"assignment1/train_Interactions.csv\"):\n",
    "  bookCount[book] += 1\n",
    "  readerCount[user] += 1\n",
    "  totalRead += 1\n",
    "\n",
    "print(\"Total num of books: {}\".format(len(bookCount)))    \n",
    "print(\"Total num of readers: {}\".format(len(readerCount))) \n",
    "print(\"Total num of reads: {}\".format(totalRead))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate lists and sets for Similarity Calculations\n",
    "\n",
    "#### Jaccard Similarity between Books\n",
    "\n",
    "Jsim(i,j) = Intersection(U_i, U_j)/ Union(U_i, U_j)  \n",
    "\n",
    "where U_i, U_j are set of readers who have read book i and book j  \n",
    "\n",
    "#### Pearson Similarity between Books\n",
    "\n",
    "\n",
    "Psim(i,j) = Sum_Product_crij((R_u_i-AR_u), (R_u_j-AR_u))/ SqRt(Sum_crij(Sq(R_u_i-AR_u)))SqRt(Sum_crij(Sq(R_u_j-AR_u)))  \n",
    "\n",
    "where \n",
    "* crij - the set of readers who have read both book i and j  \n",
    "* R_u_i = Rating that reader u gives book i  \n",
    "* AR_u = Average rating given by reader u  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................"
     ]
    }
   ],
   "source": [
    "user_Books_full = defaultdict(set)  # Set of (user, books_read)\n",
    "user_Books_Ratings_full = defaultdict(set)  # Set of (user, set(book_read, rating))\n",
    "book_Readers_full = defaultdict(set)  # Set of (book, readers)\n",
    "book_ids=[]\n",
    "reader_ids=[]\n",
    "\n",
    "i=0\n",
    "for user,book,rating in X:\n",
    "  if i % 5000 == 0:\n",
    "      print ('.', end='')\n",
    "  i += 1\n",
    "\n",
    "  user_Books_full[user].add(book)\n",
    "  user_Books_Ratings_full[user].add((book,rating))\n",
    "  book_Readers_full[book].add(user)\n",
    "  if book not in book_ids:\n",
    "        book_ids.append(book)\n",
    "  if user not in reader_ids:\n",
    "        reader_ids.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11357 7170\n"
     ]
    }
   ],
   "source": [
    "print(len(reader_ids), len(book_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_Books_train = defaultdict(set)\n",
    "user_Books_Ratings_train = defaultdict(set)\n",
    "book_Readers_train = defaultdict(set)\n",
    "book_Ratings_train = defaultdict(set)\n",
    "\n",
    "for user,book,rating in Xtrain:\n",
    "  user_Books_train[user].add(book)\n",
    "  user_Books_Ratings_train[user].add((book,rating))\n",
    "  book_Readers_train[book].add(user)\n",
    "  book_Ratings_train[book].add(rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11357, 11357, 7170, 7170)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_Books_train),len(user_Books_Ratings_train),len(book_Readers_train),len(book_Ratings_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Composition of Xtrain\n",
    "\n",
    "Some of the readers have very few datapoints. We need to augment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00b783ddd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uCount = defaultdict(int)\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book,rating in Xtrain:\n",
    "  uCount[user] += 1\n",
    "\n",
    "counts = []\n",
    "for id, count in  uCount.items():\n",
    "    counts.append(count)\n",
    "\n",
    "data = numpy.array(counts).T\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data, bins=100)\n",
    "plt.show    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a validation dataset of alternating read and unread books per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unread_books(user, read_books, n):\n",
    "    # Find n random unread books for a specific user\n",
    "    \n",
    "    books = []\n",
    "    for i in range(n):\n",
    "        book = random.choice(book_ids)  # pick a book from full library\n",
    "        while book in read_books:\n",
    "            book = random.choice(book_ids) \n",
    "        books.append(book)\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvalid_full = []\n",
    "yvalid_full = []\n",
    "\n",
    "# To augment the validation dataset, for every read reader-book pair, generate one unread reader-book pair\n",
    "for value in zip(Xvalid,yvalid):\n",
    "    x,read = value\n",
    "    user = x[0]\n",
    "    book = x[1]\n",
    "    Xvalid_full.append([user, book])\n",
    "    yvalid_full.append(read)\n",
    "    \n",
    "    books = unread_books(user, user_Books_full[user],1)\n",
    "    Xvalid_full.append([user, books[0]])\n",
    "    yvalid_full.append(0)\n",
    "    \n",
    "Xtrain_full = []\n",
    "ytrain_full = []\n",
    "\n",
    "# To augment the training dataset, for every read reader-book pair, generate two unread reader-book pair\n",
    "for value in zip(Xtrain,ytrain):\n",
    "    x,read = value\n",
    "    user = x[0]\n",
    "    book = x[1]\n",
    "    Xtrain_full.append([user, book])\n",
    "    ytrain_full.append(read)\n",
    "    \n",
    "    num_reads = len(user_Books_train[user])\n",
    "    if num_reads < 20:\n",
    "        augment = int(20*2/num_reads)\n",
    "        books = unread_books(user, user_Books_full[user],augment)\n",
    "        for book in books:\n",
    "            Xtrain_full.append([user, book])\n",
    "            ytrain_full.append(0)\n",
    "    else:\n",
    "        books = unread_books(user, user_Books_full[user],1)\n",
    "        Xtrain_full.append([user, books[0]])\n",
    "        ytrain_full.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 1] 569168\n"
     ]
    }
   ],
   "source": [
    "print(ytrain_full[:10], len(ytrain_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f00a07fdeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uCount = defaultdict(int)\n",
    "# Count the num of times a book is read, and aggregate the total num of reads\n",
    "for user,book in Xtrain_full:\n",
    "  uCount[user] += 1\n",
    "\n",
    "counts = []\n",
    "for id, count in  uCount.items():\n",
    "    counts.append(count)\n",
    "\n",
    "data = numpy.array(counts).T\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.hist(data, bins=100)\n",
    "plt.show   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_pad(l, n):\n",
    "    # if len(l) > n, the method truncates the list l to length n \n",
    "    # if n > len(l), the method pads list l with zero up to length n \n",
    "    return l[:n] + [0]*(n-len(l))\n",
    "\n",
    "def find_rating(reader,book):\n",
    "    rating = 0\n",
    "    for b, rating in user_Books_Ratings_train[reader]:\n",
    "        if book == b:\n",
    "            return int(rating)\n",
    "    return int(rating)\n",
    "\n",
    "def average_rating(reader):\n",
    "    ratings = []\n",
    "    for _, rating in user_Books_Ratings_train[reader]:\n",
    "        ratings.append(int(rating))\n",
    "    \n",
    "    if len(ratings) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return sum(ratings)/len(ratings)\n",
    "\n",
    "\"\"\"\n",
    "Jaccard Similarity\n",
    "\"\"\"\n",
    "\n",
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    return numer / denom\n",
    "\n",
    "\"\"\"\n",
    "When evaluating whether a reader will read a certain book, we can approach it in two ways:\n",
    "(1) Is the book similar to all the other books the reader has read?\n",
    "(2) Is the reader similar to all the other readers who have read the same book?\n",
    "\"\"\"\n",
    "\n",
    "def items_jsim(book1, book2):\n",
    "    # generate readers set for the 2 books based on train dataset\n",
    "    s1 = book_Readers_train[book1]\n",
    "    s2 = book_Readers_train[book2]\n",
    "    return Jaccard(s1, s2)\n",
    "\n",
    "def users_jsim(reader1, reader2):\n",
    "    # generate Books set for the 2 readers based on train dataset\n",
    "    s1 = user_Books_train[reader1]\n",
    "    s2 = user_Books_train[reader2]\n",
    "    return Jaccard(s1, s2)\n",
    "\n",
    "def jsim_mostSimilar_items(r,b):\n",
    "    # Find books read by reader r that are most similar to book b\n",
    "    # and return Jaccard(b, book) in descending order\n",
    "    jsims = []\n",
    "    \n",
    "    # Go through the books read by reader r\n",
    "    for other_book in user_Books_train[r]:\n",
    "        if b == other_book: \n",
    "           continue   # skip if the book is b\n",
    "        jsim = items_jsim(b, other_book)\n",
    "        jsims.append(jsim)\n",
    "       \n",
    "    jsims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return jsims  \n",
    "\n",
    "def jsim_mostSimilar_users(b,r):\n",
    "    # Find readers who read book b that are most similar to the reader r\n",
    "    # and return Jaccard(r, reader) in descending order\n",
    "    jsims = []\n",
    "    \n",
    "    # Go through the readers who read book b\n",
    "    for reader in book_Readers_train[b]:\n",
    "        if r == reader: \n",
    "           continue   # skip if the reader is r\n",
    "        jsim = users_jsim(r, reader)\n",
    "        jsims.append(jsim)\n",
    "       \n",
    "    jsims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return jsims  \n",
    "\n",
    "\n",
    "def jaccard_predict(user, book, threshold):\n",
    "    \"\"\"\n",
    "    user_jsims = jsim_mostSimilar_users(book,user)\n",
    "    if len(user_jsims) is 0:\n",
    "        max_jsim = 0\n",
    "    else:\n",
    "        max_jsim = user_jsims[0]\n",
    "    \"\"\"    \n",
    "    book_jsims = jsim_mostSimilar_items(user,book)\n",
    "    if len(book_jsims) is 0:\n",
    "        max_jsim = 0\n",
    "    else:\n",
    "        max_jsim = book_jsims[0]\n",
    "        \n",
    "    if max_jsim > threshold:\n",
    "        predict = True\n",
    "    else:\n",
    "        predict = False\n",
    "    return predict, max_jsim\n",
    "\n",
    "\"\"\"\n",
    "Pearson Similarity\n",
    "\n",
    "When evaluating whether a reader will read a certain book, we can approach it in two ways:\n",
    "(1) Is the book similar to all the other books the reader has read?\n",
    "(2) Is the reader similar to all the other readers who have read the same book?\n",
    "\"\"\"\n",
    "\n",
    "def users_Pearson(r1,r2):\n",
    "    \n",
    "    books_r1 = set([])\n",
    "    ratings_r1 = []\n",
    "    \n",
    "    for book,rating in user_Books_Ratings_train[r1]:\n",
    "        # print (book,rating)\n",
    "        books_r1.add(book)\n",
    "        ratings_r1.append(int(rating))\n",
    "        \n",
    "    if len(ratings_r1) == 0:\n",
    "        avRating_r1 = 0\n",
    "    else:\n",
    "        avRating_r1 = sum(ratings_r1)/len(ratings_r1)\n",
    "        \n",
    "    # print(books_r1)\n",
    "    # print(avRating_r1)\n",
    "    \n",
    "    books_r2 = set([])\n",
    "    ratings_r2 = []\n",
    "    \n",
    "    for book,rating in user_Books_Ratings_train[r2]:\n",
    "        # print (book,rating)\n",
    "        books_r2.add(book)\n",
    "        ratings_r2.append(int(rating))\n",
    "        \n",
    "    if len(ratings_r2) == 0:\n",
    "        avRating_r2 = 0\n",
    "    else:\n",
    "        avRating_r2 = sum(ratings_r2)/len(ratings_r2)  \n",
    "    \n",
    "    # print(books_r2)\n",
    "    # print(avRating_r2)\n",
    "        \n",
    "    common = books_r1.intersection(books_r2)\n",
    "    if len(common) == 0:  # return psim=0 if no common book\n",
    "        return 0\n",
    "        \n",
    "    # print(common)\n",
    "    \n",
    "    sumProducts = []\n",
    "    sumSq_R1 = []\n",
    "    sumSq_R2 = []\n",
    "    for book in common:\n",
    "        pR_r1 = find_rating(r1,book) - avRating_r1\n",
    "        pR_r2 = find_rating(r2,book) - avRating_r2\n",
    "        # print(find_rating(r1,book), pR_r1)\n",
    "        # print(find_rating(r2,book), pR_r2)\n",
    "        sumProducts.append(pR_r1*pR_r2)\n",
    "        sumSq_R1.append(pR_r1**2)\n",
    "        sumSq_R2.append(pR_r2**2)\n",
    "        \n",
    "    if sum(sumSq_R1) == 0 or sum(sumSq_R2) == 0:\n",
    "        return 0\n",
    "        \n",
    "    # print(sumProducts)\n",
    "    # print(sumSq_R1)\n",
    "    # print(sumSq_R2)\n",
    "    \n",
    "    psim = sum(sumProducts)/math.sqrt(sum(sumSq_R1)*sum(sumSq_R2))\n",
    "    return psim\n",
    "\n",
    "def items_Pearson(b1,b2):\n",
    "    \n",
    "    # Create a set of common readers for book b1 and b2\n",
    "    readers_b1 = set([])\n",
    "    for reader in book_Readers_train[b1]:\n",
    "        readers_b1.add(reader)\n",
    "        \n",
    "    readers_b2 = set([])\n",
    "    for reader in book_Readers_train[b2]:\n",
    "        readers_b2.add(reader)\n",
    "        \n",
    "    common = readers_b1.intersection(readers_b2)\n",
    "    if len(common) == 0:  # return psim=0 if no common readers\n",
    "        return 0\n",
    "        \n",
    "    # print(common)\n",
    "    \n",
    "    sumProducts = []\n",
    "    sumSq_R1 = []\n",
    "    sumSq_R2 = []\n",
    "    for reader in common:\n",
    "        avRating = average_rating(reader)\n",
    "        # print(avRating)\n",
    "        pR_b1 = find_rating(reader,b1) - avRating\n",
    "        pR_b2 = find_rating(reader,b2) - avRating\n",
    "        # print(find_rating(reader,b1), pR_b1)\n",
    "        # print(find_rating(reader,b2), pR_b2)\n",
    "        sumProducts.append(pR_b1*pR_b2)\n",
    "        sumSq_R1.append(pR_b1**2)\n",
    "        sumSq_R2.append(pR_b2**2)\n",
    "        \n",
    "    if sum(sumSq_R1) == 0 or sum(sumSq_R2) == 0:\n",
    "        return 0\n",
    "        \n",
    "    # print(sumProducts)\n",
    "    # print(sumSq_R1)\n",
    "    # print(sumSq_R2)\n",
    "    \n",
    "    psim = sum(sumProducts)/math.sqrt(sum(sumSq_R1)*sum(sumSq_R2))\n",
    "    return psim\n",
    "\n",
    "def psim_mostSimilar_users(b,r):\n",
    "    # Find readers who read book b that are most similar to the reader r\n",
    "    # and return Pearson(r, reader) in descending order\n",
    "    psims = []\n",
    "    \n",
    "    # Go through the readers who read book b\n",
    "    for reader in book_Readers_train[b]:\n",
    "        if r == reader: \n",
    "           continue   # skip if the reader is r\n",
    "        psim = users_Pearson(r, reader)\n",
    "        # print (reader, psim)\n",
    "        psims.append(psim)\n",
    "       \n",
    "    psims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return psims  \n",
    "\n",
    "def psim_mostSimilar_items(r,b):\n",
    "    # Find books read by reader r that are most similar to the book b\n",
    "    # and return Pearson(b, book) in descending order\n",
    "    psims = []\n",
    "    \n",
    "    # Go through the books read by reader r \n",
    "    for book in user_Books_train[r]:\n",
    "        if book == b: \n",
    "           continue   # skip if the book is b\n",
    "        psim = items_Pearson(b, book)\n",
    "        # print (book, psim)\n",
    "        psims.append(psim)\n",
    "       \n",
    "    psims.sort(reverse=True)  # sort in descending order of Jaccard Similarity\n",
    "    return psims  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................\n",
      "\n",
      ".."
     ]
    }
   ],
   "source": [
    "U_Jsims_train = []\n",
    "U_Psims_train = []\n",
    "B_Jsims_train = []\n",
    "B_Psims_train = []\n",
    "\n",
    "U_Jsims_valid = []\n",
    "U_Psims_valid = []\n",
    "B_Jsims_valid = []\n",
    "B_Psims_valid = []\n",
    "\n",
    "i=0\n",
    "for u,b in Xtrain_full:\n",
    "    if i % 10000 == 0:\n",
    "        print ('.', end='')\n",
    "    i += 1\n",
    "    \n",
    "    U_Jsims_train.append(list_pad(jsim_mostSimilar_users(b,u),8))\n",
    "    U_Psims_train.append(list_pad(psim_mostSimilar_users(b,u),8))    \n",
    "    B_Jsims_train.append(list_pad(jsim_mostSimilar_items(u,b),8))\n",
    "    B_Psims_train.append(list_pad(psim_mostSimilar_items(u,b),8))\n",
    "    \n",
    "print ('\\n')\n",
    "i=0\n",
    "for u,b in Xvalid_full:\n",
    "    if i % 10000 == 0:\n",
    "        print ('.', end='')\n",
    "    i += 1\n",
    "    U_Jsims_valid.append(list_pad(jsim_mostSimilar_users(b,u),8))\n",
    "    U_Psims_valid.append(list_pad(psim_mostSimilar_users(b,u),8))    \n",
    "    B_Jsims_valid.append(list_pad(jsim_mostSimilar_items(u,b),8)) \n",
    "    B_Psims_valid.append(list_pad(psim_mostSimilar_items(u,b),8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Logistic Regression Model - Popularity Only\n",
    "\n",
    "Start simple:\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [popularity], popularity= (times a book is read)/(total num of reads)\n",
    "\n",
    "Accuracy = 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.000235], [1, 6.5e-05], [1, 6e-05], [1, 0.00012], [1, 9e-05], [1, 0.0006], [1, 0.00022], [1, 3e-05], [1, 0.00012], [1, 0.000365]]\n"
     ]
    }
   ],
   "source": [
    "X_train = [[1,bookCount[x]/totalRead] for _,x in Xtrain_full]\n",
    "y_train = ytrain_full\n",
    "\n",
    "X_valid = [[1,bookCount[x]/totalRead] for _,x in Xvalid_full]\n",
    "y_valid = yvalid_full\n",
    "\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 7e-06\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 8e-06\n",
      "Training:\n",
      "Accuracy: 0.6818900570657521\n",
      "Validation:\n",
      "Accuracy: 0.6617161716171617\n",
      "\n",
      "\n",
      "Regularization = 9e-06\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.6888598796840301\n",
      "Validation:\n",
      "Accuracy: 0.6620662066206621\n",
      "\n",
      "\n",
      "Regularization = 1.2e-05\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 0.001\n",
      "Training:\n",
      "Accuracy: 0.7095356731228741\n",
      "Validation:\n",
      "Accuracy: 0.6503150315031503\n",
      "\n",
      "\n",
      "Regularization = 0.01\n",
      "Training:\n",
      "Accuracy: 0.7095356731228741\n",
      "Validation:\n",
      "Accuracy: 0.6503150315031503\n",
      "\n",
      "\n",
      "Regularization = 0.1\n",
      "Training:\n",
      "Accuracy: 0.7095356731228741\n",
      "Validation:\n",
      "Accuracy: 0.6503150315031503\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 7e-6, 8e-6, 9e-6, 1e-5, 1.2e-5,1e-4, 1e-3, 0.01, 0.1]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Logistic Regression Model - Popularity+ Books' JSim + Users' JSim\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [book_popularity, user_similarity_1,user_similarity_2, book_similarity_1,book_similarity_2] \n",
    "\n",
    "book_popularity= (times a book is read)/(total num of reads)  \n",
    "user_similarity_1 = Jaccard similarity of the user and the most similar user who read the book  \n",
    "user_similarity_2 = Jaccard similarity of the user and the 2nd most similar user who read the book  \n",
    "book_similarity_1 = Jaccard similarity of the book and the most similar book read by the reader  \n",
    "book_similarity_2 = Jaccard similarity of the book and 2nd most similar book read by the reader  \n",
    "\n",
    "and so on ...  \n",
    "\n",
    "Accuracy = 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, user_jsims[0], user_jsims[1], user_jsims[2], user_jsims[3]])\n",
    "y_valid = yvalid_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.6454930705872431\n",
      "Validation:\n",
      "Accuracy: 0.64001400140014\n",
      "\n",
      "\n",
      "Regularization = 2e-06\n",
      "Training:\n",
      "Accuracy: 0.7426454052230624\n",
      "Validation:\n",
      "Accuracy: 0.6744674467446745\n",
      "\n",
      "\n",
      "Regularization = 3e-06\n",
      "Training:\n",
      "Accuracy: 0.7921720827593962\n",
      "Validation:\n",
      "Accuracy: 0.681968196819682\n",
      "\n",
      "\n",
      "Regularization = 4e-06\n",
      "Training:\n",
      "Accuracy: 0.8234897253534984\n",
      "Validation:\n",
      "Accuracy: 0.6826682668266827\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n",
      "Training:\n",
      "Accuracy: 0.8443886515053551\n",
      "Validation:\n",
      "Accuracy: 0.67996799679968\n",
      "\n",
      "\n",
      "Regularization = 6e-06\n",
      "Training:\n",
      "Accuracy: 0.8588975487026678\n",
      "Validation:\n",
      "Accuracy: 0.677967796779678\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.8889291035335788\n",
      "Validation:\n",
      "Accuracy: 0.6614161416141614\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.9174303544823321\n",
      "Validation:\n",
      "Accuracy: 0.607960796079608\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 2e-6, 3e-6, 4e-6, 5e-6, 6e-6, 1e-5, 1e-4]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_valid = yvalid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.6516107722148821\n",
      "Validation:\n",
      "Accuracy: 0.6413641364136413\n",
      "\n",
      "\n",
      "Regularization = 2e-06\n",
      "Training:\n",
      "Accuracy: 0.7494887274056167\n",
      "Validation:\n",
      "Accuracy: 0.6756675667566757\n",
      "\n",
      "\n",
      "Regularization = 3e-06\n",
      "Training:\n",
      "Accuracy: 0.8043354510443314\n",
      "Validation:\n",
      "Accuracy: 0.6851685168516851\n",
      "\n",
      "\n",
      "Regularization = 4e-06\n",
      "Training:\n",
      "Accuracy: 0.8381022826300846\n",
      "Validation:\n",
      "Accuracy: 0.6882688268826883\n",
      "\n",
      "\n",
      "Regularization = 5e-06\n",
      "Training:\n",
      "Accuracy: 0.8609092570207741\n",
      "Validation:\n",
      "Accuracy: 0.6833683368336834\n",
      "\n",
      "\n",
      "Regularization = 7e-06\n",
      "Training:\n",
      "Accuracy: 0.8891926461080033\n",
      "Validation:\n",
      "Accuracy: 0.6753675367536753\n",
      "\n",
      "\n",
      "Regularization = 9e-06\n",
      "Training:\n",
      "Accuracy: 0.9057589323363225\n",
      "Validation:\n",
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.9115955218845754\n",
      "Validation:\n",
      "Accuracy: 0.6623162316231623\n",
      "\n",
      "\n",
      "Regularization = 1.1e-05\n",
      "Training:\n",
      "Accuracy: 0.9165395805807776\n",
      "Validation:\n",
      "Accuracy: 0.6590659065906591\n",
      "\n",
      "\n",
      "Regularization = 1.2e-05\n",
      "Training:\n",
      "Accuracy: 0.9206174626823714\n",
      "Validation:\n",
      "Accuracy: 0.6556655665566556\n",
      "\n",
      "\n",
      "Regularization = 1.3e-05\n",
      "Training:\n",
      "Accuracy: 0.924043516149889\n",
      "Validation:\n",
      "Accuracy: 0.6535653565356536\n",
      "\n",
      "\n",
      "Regularization = 1.4e-05\n",
      "Training:\n",
      "Accuracy: 0.9267773311219183\n",
      "Validation:\n",
      "Accuracy: 0.6498649864986499\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.9530911787029489\n",
      "Validation:\n",
      "Accuracy: 0.6003600360036003\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambs = [1e-6, 2e-6, 3e-6, 4e-6, 5e-6, 7e-6, 9e-6, 1e-5, 1.1e-5, 1.2e-5, 1.3e-5, 1.4e-5, 1e-4]\n",
    "\n",
    "for lamb in lambs:\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission, Accuracy=0.695, User_Name='Luke Liem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=[]\n",
    "books=[]\n",
    "X_test=[]\n",
    "\n",
    "model = linear_model.LogisticRegression(C=4e-6, class_weight='balanced',solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = open(\"assignment1/predictions_Read.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Read.txt\"):\n",
    "\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    \n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    users.append(u)\n",
    "    books.append(b)\n",
    "    \n",
    "    # Predict using Jaccard similarity\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),8)\n",
    "    book_jsims = list_pad(jsim_mostSimilar_items(u,b),8)\n",
    "    X_test.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "for u,b,pred in zip(users,books,test_pred):\n",
    "        predictions.write(u + '-' + b + \",\" + str(pred) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) Logistic Regression Model - Popularity+ Books' JSim + Users' JSim\n",
    "\n",
    "X.theta = y\n",
    "\n",
    "where X = [book_popularity, user_Jsim_1,user_Jsim_2, book_Jsim_1,book_Jsim_2, user_Psim_1,user_Psim_2] \n",
    "\n",
    "book_popularity= (times a book is read)/(total num of reads)  \n",
    "user_Jsim_1 = Jaccard similarity of the user and the most similar user who read the book  \n",
    "user_Jsim_2 = Jaccard similarity of the user and the 2nd most similar user who read the book  \n",
    "book_Jsim_1 = Jaccard similarity of the book and the most similar book read by the reader  \n",
    "book_Jsim_2 = Jaccard similarity of the book and 2nd most similar book read by the reader \n",
    "user_Psim_1 = Pearson similarity of the user and the most similar user who read the book  \n",
    "user_Psim_2 = Pearson similarity of the user and the 2nd most similar user who read the book \n",
    "\n",
    "and so on ...  \n",
    "\n",
    "The Pearson Similarity seems pretty useless!!!\n",
    "\n",
    "Accuracy = 0.622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_valid = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    user_jsims[5],user_jsims[6],user_jsims[7], \\\n",
    "                    book_jsims[0], book_jsims[1], \\\n",
    "#                    user_psims[0],user_psims[1],user_psims[2],user_psims[3],user_psims[4], \\\n",
    "                   ])\n",
    "y_train = ytrain_full\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    user_jsims[5],user_jsims[6],user_jsims[7], \\\n",
    "                    book_jsims[0], book_jsims[1], \\\n",
    "#                    user_psims[0],user_psims[1],user_psims[2],user_psims[3],user_psims[4], \\\n",
    "                   ])\n",
    "y_valid = yvalid_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization = 1e-08\n",
      "Training:\n",
      "Accuracy: 0.333822351221432\n",
      "Validation:\n",
      "Accuracy: 0.5\n",
      "\n",
      "\n",
      "Regularization = 1e-07\n",
      "Training:\n",
      "Accuracy: 0.5414868720658926\n",
      "Validation:\n",
      "Accuracy: 0.5915591559155916\n",
      "\n",
      "\n",
      "Regularization = 1e-06\n",
      "Training:\n",
      "Accuracy: 0.7000323278891294\n",
      "Validation:\n",
      "Accuracy: 0.6587658765876587\n",
      "\n",
      "\n",
      "Regularization = 1.2e-06\n",
      "Training:\n",
      "Accuracy: 0.7276463188373204\n",
      "Validation:\n",
      "Accuracy: 0.6695169516951696\n",
      "\n",
      "\n",
      "Regularization = 1.3e-06\n",
      "Training:\n",
      "Accuracy: 0.7402348691423271\n",
      "Validation:\n",
      "Accuracy: 0.6729672967296729\n",
      "\n",
      "\n",
      "Regularization = 1.4e-06\n",
      "Training:\n",
      "Accuracy: 0.7521557782587918\n",
      "Validation:\n",
      "Accuracy: 0.6764176417641764\n",
      "\n",
      "\n",
      "Regularization = 1.5e-06\n",
      "Training:\n",
      "Accuracy: 0.7629452112557277\n",
      "Validation:\n",
      "Accuracy: 0.6793679367936794\n",
      "\n",
      "\n",
      "Regularization = 1e-05\n",
      "Training:\n",
      "Accuracy: 0.9417201950917831\n",
      "Validation:\n",
      "Accuracy: 0.6431643164316432\n",
      "\n",
      "\n",
      "Regularization = 0.0001\n",
      "Training:\n",
      "Accuracy: 0.9611731509852979\n",
      "Validation:\n",
      "Accuracy: 0.5941094109410942\n",
      "\n",
      "\n",
      "Regularization = 0.001\n",
      "Training:\n",
      "Accuracy: 0.964282953363506\n",
      "Validation:\n",
      "Accuracy: 0.5896089608960896\n",
      "\n",
      "\n",
      "Regularization = 0.01\n",
      "Training:\n",
      "Accuracy: 0.9710085598628173\n",
      "Validation:\n",
      "Accuracy: 0.5932593259325932\n",
      "\n",
      "\n",
      "Regularization = 0.05\n",
      "Training:\n",
      "Accuracy: 0.9763479324206561\n",
      "Validation:\n",
      "Accuracy: 0.5863586358635864\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lambs = [1e-7, 1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 1e-3, 1.5e-3, 2e-3, 2.5e-3, 5e-3, 0.01, 0.025, 0.05]\n",
    "# [1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "#                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "#                    book_jsims[0],book_jsims[1], \\\n",
    "#                   ])\n",
    "# Regularization = 5e-06; Accuracy: 0.682018201820182\n",
    "\n",
    "lambs = [1e-8, 1e-7, 1e-6, 1.2e-6, 1.3e-6,  1.4e-6,  1.5e-6, 1e-5, 1e-4, 1e-3, 0.01, 0.05]\n",
    "\n",
    "for lamb in lambs:\n",
    "\n",
    "    print(\"Regularization = {}\".format(lamb))\n",
    "    model = linear_model.LogisticRegression(max_iter = 1000, C=lamb, class_weight='balanced',solver='liblinear')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = model.predict(X_train)\n",
    "    valid_pred = model.predict(X_valid)\n",
    "\n",
    "    print(\"Training:\")\n",
    "    calc_model_stats(train_pred,y_train)\n",
    "\n",
    "    print(\"Validation:\")\n",
    "    calc_model_stats(valid_pred,y_valid)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1e-05, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [[1,bookCount[x]/totalRead] for _,x in Xtrain_full]\n",
    "y_train = ytrain_full\n",
    "\n",
    "model1 = linear_model.LogisticRegression(C=1e-05, class_weight='balanced',solver='liblinear')\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4e-06, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_train = ytrain_full\n",
    "\n",
    "model2 = linear_model.LogisticRegression(C=4e-6, class_weight='balanced',solver='liblinear')\n",
    "model2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.5e-06, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xtrain_full, U_Jsims_train,U_Psims_train, \\\n",
    "                                                             B_Jsims_train,B_Psims_train):\n",
    "    X_train.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    user_jsims[5],user_jsims[6],user_jsims[7], \\\n",
    "                    book_jsims[0], book_jsims[1], \\\n",
    "#                    user_psims[0],user_psims[1],user_psims[2],user_psims[3],user_psims[4], \\\n",
    "                   ])\n",
    "y_train = ytrain_full\n",
    "\n",
    "model3 = linear_model.LogisticRegression(C=1.5e-06, class_weight='balanced',solver='liblinear')\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = [[1,bookCount[x]/totalRead] for _,x in Xvalid_full]\n",
    "y_valid = yvalid_full\n",
    "\n",
    "valid_pred1 = model1.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "y_valid = yvalid_full\n",
    "\n",
    "valid_pred2 = model2.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = []\n",
    "for (u,b),user_jsims,user_psims,book_jsims,book_psims in zip(Xvalid_full, U_Jsims_valid,U_Psims_valid, \\\n",
    "                                                             B_Jsims_valid,B_Psims_valid):\n",
    "    X_valid.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    user_jsims[5],user_jsims[6],user_jsims[7], \\\n",
    "                    book_jsims[0], book_jsims[1], \\\n",
    "#                    user_psims[0],user_psims[1],user_psims[2],user_psims[3],user_psims[4], \\\n",
    "                   ])\n",
    "y_valid = yvalid_full\n",
    "\n",
    "valid_pred3 = model3.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6912191219121913\n"
     ]
    }
   ],
   "source": [
    "ensemble_pred = [1 if (y1+y2+y3)>1 else 0 for y1,y2,y3 in zip(valid_pred1,valid_pred2,valid_pred3)]\n",
    "\n",
    "calc_model_stats(ensemble_pred,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission, Accuracy=0.698, User_Name='Luke Liem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=[]\n",
    "books=[]\n",
    "X_test1=[]\n",
    "X_test2=[]\n",
    "X_test3=[]\n",
    "\n",
    "# model = linear_model.LogisticRegression(C=4e-6, class_weight='balanced',solver='liblinear')\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "predictions = open(\"assignment1/predictions_Read.txt\", 'w')\n",
    "for l in open(\"assignment1/pairs_Read.txt\"):\n",
    "\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    \n",
    "    u,b = l.strip().split('-')\n",
    "    \n",
    "    users.append(u)\n",
    "    books.append(b)\n",
    "    \n",
    "    # Predict using Jaccard similarity\n",
    "    user_jsims = list_pad(jsim_mostSimilar_users(b,u),8)\n",
    "    book_jsims = list_pad(jsim_mostSimilar_items(u,b),8)\n",
    "    X_test1.append([1, bookCount[b]/totalRead])\n",
    "    X_test2.append([1, bookCount[b]/totalRead, \\\n",
    "                    # readerCount[u]/totalRead, \\\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    book_jsims[0], book_jsims[1]])\n",
    "    X_test3.append([1, bookCount[b]/totalRead, readerCount[u]/totalRead,\n",
    "                    user_jsims[0],user_jsims[1],user_jsims[2],user_jsims[3],user_jsims[4], \\\n",
    "                    user_jsims[5],user_jsims[6],user_jsims[7], \\\n",
    "                    book_jsims[0], book_jsims[1], \\\n",
    "                   ])\n",
    "\n",
    "test_pred1 = model1.predict(X_test1)\n",
    "test_pred2 = model2.predict(X_test2)\n",
    "test_pred3 = model3.predict(X_test3)\n",
    "\n",
    "ensemble_pred = [1 if (y1+y2+y3)>1 else 0 for y1,y2,y3 in zip(test_pred1,test_pred2,test_pred3)]\n",
    "\n",
    "for u,b,pred in zip(users,books,ensemble_pred):\n",
    "        predictions.write(u + '-' + b + \",\" + str(pred) + \"\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
