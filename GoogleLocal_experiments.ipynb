{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Alpha-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpha_Only(nn.Module):\n",
    "    \n",
    "    def __init__(self, mean=0):\n",
    "        super(Alpha_Only, self).__init__()\n",
    "        \n",
    "        # alpha only\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        item_id = train_x[:, 0]\n",
    "        user_id = train_x[:, 1]\n",
    "        \n",
    "        prediction = (self.bias)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        return F.mse_loss(prediction, target.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Alpha_Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alpha_Theta(nn.Module):\n",
    "    \n",
    "    def __init__(self, mean=0):\n",
    "        super(Alpha_Theta, self).__init__()\n",
    "        \n",
    "        # alpha + theta only\n",
    "        self.theta = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        freq = train_x[:, 2].float()\n",
    "        \n",
    "        prediction = (self.bias)+self.theta*freq\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        return F.mse_loss(prediction, target.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3 - Alpha_Theta_MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_theta(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_user, n_item, k=1):\n",
    "        super(MF_theta, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        \n",
    "        # gammas (users and items)\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "        \n",
    "        # alpha and betas (users and items)\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        \n",
    "        self.theta = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        item_id = train_x[:, 0]\n",
    "        user_id = train_x[:, 1]\n",
    "        freq = train_x[:, 2].float()\n",
    "        vector_user = self.user(user_id)\n",
    "        vector_item = self.item(item_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + self.theta*freq + bias_user + bias_item)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        return F.mse_loss(prediction, target.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4 - Alpha_Theta_Betas_MF\n",
    "\n",
    "Incorporate biases for month and day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_theta_betas_time(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_user, n_item, k=1):\n",
    "        super(MF_theta_betas_time, self).__init__()\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        \n",
    "        # gammas (users and items)\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "        \n",
    "        # alpha and betas (users and items)\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        # betas (month and day)\n",
    "        self.bias_month = nn.Embedding(12, 1)\n",
    "        self.bias_day = nn.Embedding(31, 1)\n",
    "        \n",
    "        self.theta = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        item_id = train_x[:, 0]\n",
    "        user_id = train_x[:, 1]\n",
    "        freq = train_x[:, 2].float()\n",
    "        month = train_x[:, 3]-1\n",
    "        day = train_x[:, 4]-1\n",
    "        \n",
    "        vector_user = self.user(user_id)\n",
    "        vector_item = self.item(item_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "\n",
    "        bias_month = self.bias_month(month).squeeze()\n",
    "        bias_day = self.bias_day(day).squeeze()\n",
    "        \n",
    "        biases = (self.bias + self.theta*freq + bias_user + bias_item + bias_month + bias_day)\n",
    "        \n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Add bias prediction to the interaction prediction\n",
    "        prediction = ui_interaction + biases\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        return F.mse_loss(prediction, target.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11453845 entries, 0 to 11453844\n",
      "Data columns (total 5 columns):\n",
      "gPlusPlaceId      int64\n",
      "gPlusUserId       int64\n",
      "rating            float64\n",
      "unixReviewTime    object\n",
      "num_reviews       int64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 436.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368311</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1372686659</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>370282</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1342870724</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237940</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1390653513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249417</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1389187706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1181533</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1390486279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gPlusPlaceId  gPlusUserId  rating unixReviewTime  num_reviews\n",
       "0       1368311            0     3.0     1372686659            3\n",
       "1        370282            1     5.0     1342870724            3\n",
       "2        237940            2     5.0     1390653513            1\n",
       "3        249417            2     5.0     1389187706            2\n",
       "4       1181533            2     4.0     1390486279            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/google_local/reviews_freq.csv\")\n",
    "display(data.info())\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5054567 3116785\n"
     ]
    }
   ],
   "source": [
    "n_user = len(data['gPlusUserId'].unique())\n",
    "n_place = len(data['gPlusPlaceId'].unique())\n",
    "\n",
    "print(n_user,n_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11453845 8017692 1718077 1718076\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_data.head()\n",
    "\n",
    "N = shuffled_data.index.size\n",
    "\n",
    "train_split = int(N * 0.70)\n",
    "valid_split =  int(N * 0.85)\n",
    "\n",
    "train_x = shuffled_data.loc[:train_split, ['gPlusPlaceId','gPlusUserId','num_reviews']]\n",
    "train_y = shuffled_data.loc[:train_split, 'rating':'rating']\n",
    "valid_x = shuffled_data.loc[train_split+1:valid_split, ['gPlusPlaceId','gPlusUserId','num_reviews']]\n",
    "valid_y = shuffled_data.loc[train_split+1:valid_split, 'rating':'rating']\n",
    "test_x = shuffled_data.loc[valid_split+1:, ['gPlusPlaceId','gPlusUserId','num_reviews']]\n",
    "test_y = shuffled_data.loc[valid_split+1:, 'rating':'rating']\n",
    "\n",
    "print(N, train_x.index.size, valid_x.index.size,test_x.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4304410013519473"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(valid_y[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10601852 entries, 0 to 10601851\n",
      "Data columns (total 8 columns):\n",
      "gPlusPlaceId      int64\n",
      "gPlusUserId       int64\n",
      "rating            int64\n",
      "unixReviewTime    int64\n",
      "num_reviews       int64\n",
      "year              int64\n",
      "month             int64\n",
      "day               int64\n",
      "dtypes: int64(8)\n",
      "memory usage: 647.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>rating</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804813</td>\n",
       "      <td>2021440</td>\n",
       "      <td>4</td>\n",
       "      <td>662601600</td>\n",
       "      <td>9</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1918972</td>\n",
       "      <td>389663</td>\n",
       "      <td>4</td>\n",
       "      <td>662601600</td>\n",
       "      <td>20</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>449452</td>\n",
       "      <td>2709545</td>\n",
       "      <td>4</td>\n",
       "      <td>662601600</td>\n",
       "      <td>15</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>942354</td>\n",
       "      <td>4936600</td>\n",
       "      <td>4</td>\n",
       "      <td>662601600</td>\n",
       "      <td>293</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3063673</td>\n",
       "      <td>828378</td>\n",
       "      <td>5</td>\n",
       "      <td>662601600</td>\n",
       "      <td>11</td>\n",
       "      <td>1990</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gPlusPlaceId  gPlusUserId  rating  unixReviewTime  num_reviews  year  \\\n",
       "0        804813      2021440       4       662601600            9  1990   \n",
       "1       1918972       389663       4       662601600           20  1990   \n",
       "2        449452      2709545       4       662601600           15  1990   \n",
       "3        942354      4936600       4       662601600          293  1990   \n",
       "4       3063673       828378       5       662601600           11  1990   \n",
       "\n",
       "   month  day  \n",
       "0     12   31  \n",
       "1     12   31  \n",
       "2     12   31  \n",
       "3     12   31  \n",
       "4     12   31  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/google_local/reviews_timesorted.csv\")\n",
    "display(data.info())\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10601852 7421297 1590278 1590277\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_data.head()\n",
    "\n",
    "N = shuffled_data.index.size\n",
    "\n",
    "train_split = int(N * 0.70)\n",
    "valid_split =  int(N * 0.85)\n",
    "\n",
    "train_x = shuffled_data.loc[:train_split, ['gPlusPlaceId','gPlusUserId','num_reviews','month','day']]\n",
    "train_y = shuffled_data.loc[:train_split, 'rating':'rating']\n",
    "valid_x = shuffled_data.loc[train_split+1:valid_split, ['gPlusPlaceId','gPlusUserId','num_reviews','month','day']]\n",
    "valid_y = shuffled_data.loc[train_split+1:valid_split, 'rating':'rating']\n",
    "test_x = shuffled_data.loc[valid_split+1:, ['gPlusPlaceId','gPlusUserId','num_reviews','month','day']]\n",
    "test_y = shuffled_data.loc[valid_split+1:, 'rating':'rating']\n",
    "\n",
    "print(N, train_x.index.size, valid_x.index.size,test_x.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>gPlusUserId</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3095652</td>\n",
       "      <td>2746612</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299358</td>\n",
       "      <td>1244207</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2999233</td>\n",
       "      <td>3154701</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606464</td>\n",
       "      <td>2845190</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1209131</td>\n",
       "      <td>1218171</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2995954</td>\n",
       "      <td>133252</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>885979</td>\n",
       "      <td>3977617</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2623553</td>\n",
       "      <td>3531237</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>425287</td>\n",
       "      <td>300643</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1403888</td>\n",
       "      <td>3290531</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gPlusPlaceId  gPlusUserId  num_reviews  month  day\n",
       "0       3095652      2746612            5      7   19\n",
       "1        299358      1244207            9     12   17\n",
       "2       2999233      3154701           20      3   19\n",
       "3        606464      2845190           13      7   26\n",
       "4       1209131      1218171           24      6   19\n",
       "5       2995954       133252           14      6   14\n",
       "6        885979      3977617           18      7   11\n",
       "7       2623553      3531237            6      1   12\n",
       "8        425287       300643           23      1   22\n",
       "9       1403888      3290531            5      9   10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 5e-3\n",
    "k = 1\n",
    "lamb = 5e-7\n",
    "batch_size = 1024\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print (cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] Iteration[0] Training Loss: 2393.26\n",
      "Epoch[0] Validation Loss: 2258.248 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[1000] Training Loss: 2.49\n",
      "Epoch[0] Validation Loss: 2.647 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[2000] Training Loss: 1.62\n",
      "Epoch[0] Validation Loss: 1.607 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[3000] Training Loss: 1.52\n",
      "Epoch[0] Validation Loss: 1.522 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[4000] Training Loss: 1.63\n",
      "Epoch[0] Validation Loss: 1.457 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[5000] Training Loss: 1.37\n",
      "Epoch[0] Validation Loss: 1.400 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[6000] Training Loss: 1.32\n",
      "Epoch[0] Validation Loss: 1.352 \n",
      "Save best theta...\n",
      "Epoch[0] Iteration[7000] Training Loss: 1.38\n",
      "Epoch[0] Validation Loss: 1.313 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[0] Training Loss: 0.95\n",
      "Epoch[1] Validation Loss: 1.304 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[1000] Training Loss: 0.84\n",
      "Epoch[1] Validation Loss: 1.287 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[2000] Training Loss: 0.98\n",
      "Epoch[1] Validation Loss: 1.272 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[3000] Training Loss: 1.00\n",
      "Epoch[1] Validation Loss: 1.260 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[4000] Training Loss: 1.29\n",
      "Epoch[1] Validation Loss: 1.250 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[5000] Training Loss: 0.92\n",
      "Epoch[1] Validation Loss: 1.239 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[6000] Training Loss: 1.12\n",
      "Epoch[1] Validation Loss: 1.238 \n",
      "Save best theta...\n",
      "Epoch[1] Iteration[7000] Training Loss: 1.17\n",
      "Epoch[1] Validation Loss: 1.225 \n",
      "Save best theta...\n",
      "Epoch[2] Iteration[0] Training Loss: 0.74\n",
      "Epoch[2] Validation Loss: 1.232 \n",
      "Epoch[2] Iteration[1000] Training Loss: 0.88\n",
      "Epoch[2] Validation Loss: 1.230 \n",
      "Epoch[2] Iteration[2000] Training Loss: 0.86\n",
      "Epoch[2] Validation Loss: 1.232 \n",
      "Epoch[2] Iteration[3000] Training Loss: 0.81\n",
      "Epoch[2] Validation Loss: 1.231 \n",
      "Epoch[2] Iteration[4000] Training Loss: 1.11\n",
      "Epoch[2] Validation Loss: 1.227 \n",
      "Epoch[2] Iteration[5000] Training Loss: 1.01\n",
      "Epoch[2] Validation Loss: 1.223 \n",
      "Save best theta...\n",
      "Epoch[2] Iteration[6000] Training Loss: 1.05\n",
      "Epoch[2] Validation Loss: 1.219 \n",
      "Save best theta...\n",
      "Epoch[2] Iteration[7000] Training Loss: 1.19\n",
      "Epoch[2] Validation Loss: 1.220 \n",
      "Epoch[3] Iteration[0] Training Loss: 0.91\n",
      "Epoch[3] Validation Loss: 1.215 \n",
      "Save best theta...\n",
      "Epoch[3] Iteration[1000] Training Loss: 0.84\n",
      "Epoch[3] Validation Loss: 1.228 \n",
      "Epoch[3] Iteration[2000] Training Loss: 0.75\n",
      "Epoch[3] Validation Loss: 1.225 \n",
      "Epoch[3] Iteration[3000] Training Loss: 0.96\n",
      "Epoch[3] Validation Loss: 1.227 \n",
      "Epoch[3] Iteration[4000] Training Loss: 1.13\n",
      "Epoch[3] Validation Loss: 1.225 \n",
      "Epoch[3] Iteration[5000] Training Loss: 1.00\n",
      "Epoch[3] Validation Loss: 1.221 \n",
      "Epoch[3] Iteration[6000] Training Loss: 0.98\n",
      "Epoch[3] Validation Loss: 1.218 \n",
      "Epoch[3] Iteration[7000] Training Loss: 0.99\n",
      "Epoch[3] Validation Loss: 1.214 \n",
      "Save best theta...\n",
      "Epoch[4] Iteration[0] Training Loss: 0.94\n",
      "Epoch[4] Validation Loss: 1.213 \n",
      "Save best theta...\n",
      "Epoch[4] Iteration[1000] Training Loss: 1.01\n",
      "Epoch[4] Validation Loss: 1.224 \n",
      "Epoch[4] Iteration[2000] Training Loss: 0.88\n",
      "Epoch[4] Validation Loss: 1.225 \n",
      "Epoch[4] Iteration[3000] Training Loss: 1.00\n",
      "Epoch[4] Validation Loss: 1.229 \n",
      "Epoch[4] Iteration[4000] Training Loss: 0.92\n",
      "Epoch[4] Validation Loss: 1.232 \n",
      "Epoch[4] Iteration[5000] Training Loss: 1.07\n",
      "Epoch[4] Validation Loss: 1.222 \n",
      "Epoch[4] Iteration[6000] Training Loss: 1.16\n",
      "Epoch[4] Validation Loss: 1.234 \n",
      "Epoch[4] Iteration[7000] Training Loss: 1.21\n",
      "Epoch[4] Validation Loss: 1.214 \n",
      "Epoch[5] Iteration[0] Training Loss: 0.80\n",
      "Epoch[5] Validation Loss: 1.215 \n",
      "Epoch[5] Iteration[1000] Training Loss: 0.95\n",
      "Epoch[5] Validation Loss: 1.222 \n",
      "Epoch[5] Iteration[2000] Training Loss: 0.80\n",
      "Epoch[5] Validation Loss: 1.253 \n",
      "Epoch[5] Iteration[3000] Training Loss: 0.90\n",
      "Epoch[5] Validation Loss: 1.226 \n",
      "Epoch[5] Iteration[4000] Training Loss: 1.02\n",
      "Epoch[5] Validation Loss: 1.225 \n",
      "Epoch[5] Iteration[5000] Training Loss: 1.13\n",
      "Epoch[5] Validation Loss: 1.251 \n",
      "Epoch[5] Iteration[6000] Training Loss: 1.05\n",
      "Epoch[5] Validation Loss: 1.237 \n",
      "Epoch[5] Iteration[7000] Training Loss: 1.21\n",
      "Epoch[5] Validation Loss: 1.214 \n",
      "Epoch[6] Iteration[0] Training Loss: 0.76\n",
      "Epoch[6] Validation Loss: 1.216 \n",
      "Epoch[6] Iteration[1000] Training Loss: 0.96\n",
      "Epoch[6] Validation Loss: 1.226 \n",
      "Epoch[6] Iteration[2000] Training Loss: 1.13\n",
      "Epoch[6] Validation Loss: 1.227 \n",
      "Epoch[6] Iteration[3000] Training Loss: 0.92\n",
      "Epoch[6] Validation Loss: 1.228 \n",
      "Epoch[6] Iteration[4000] Training Loss: 1.04\n",
      "Epoch[6] Validation Loss: 1.224 \n",
      "Epoch[6] Iteration[5000] Training Loss: 1.12\n",
      "Epoch[6] Validation Loss: 1.226 \n",
      "Epoch[6] Iteration[6000] Training Loss: 1.11\n",
      "Epoch[6] Validation Loss: 1.222 \n",
      "Epoch[6] Iteration[7000] Training Loss: 0.99\n",
      "Epoch[6] Validation Loss: 1.215 \n",
      "Epoch[7] Iteration[0] Training Loss: 0.86\n",
      "Epoch[7] Validation Loss: 1.222 \n",
      "Epoch[7] Iteration[1000] Training Loss: 0.84\n",
      "Epoch[7] Validation Loss: 1.227 \n",
      "Epoch[7] Iteration[2000] Training Loss: 0.92\n",
      "Epoch[7] Validation Loss: 1.226 \n",
      "Epoch[7] Iteration[3000] Training Loss: 1.00\n",
      "Epoch[7] Validation Loss: 1.227 \n",
      "Epoch[7] Iteration[4000] Training Loss: 1.11\n",
      "Epoch[7] Validation Loss: 1.226 \n",
      "Epoch[7] Iteration[5000] Training Loss: 1.17\n",
      "Epoch[7] Validation Loss: 1.225 \n",
      "Epoch[7] Iteration[6000] Training Loss: 1.08\n",
      "Epoch[7] Validation Loss: 1.219 \n",
      "Epoch[7] Iteration[7000] Training Loss: 1.15\n",
      "Epoch[7] Validation Loss: 1.215 \n",
      "Epoch[8] Iteration[0] Training Loss: 1.04\n",
      "Epoch[8] Validation Loss: 1.219 \n",
      "Epoch[8] Iteration[1000] Training Loss: 0.92\n",
      "Epoch[8] Validation Loss: 1.222 \n",
      "Epoch[8] Iteration[2000] Training Loss: 1.02\n",
      "Epoch[8] Validation Loss: 1.227 \n",
      "Epoch[8] Iteration[3000] Training Loss: 0.99\n",
      "Epoch[8] Validation Loss: 1.232 \n",
      "Epoch[8] Iteration[4000] Training Loss: 1.04\n",
      "Epoch[8] Validation Loss: 1.226 \n",
      "Epoch[8] Iteration[5000] Training Loss: 1.02\n",
      "Epoch[8] Validation Loss: 1.225 \n",
      "Epoch[8] Iteration[6000] Training Loss: 1.04\n",
      "Epoch[8] Validation Loss: 1.219 \n",
      "Epoch[8] Iteration[7000] Training Loss: 1.18\n",
      "Epoch[8] Validation Loss: 1.215 \n",
      "Epoch[9] Iteration[0] Training Loss: 0.79\n",
      "Epoch[9] Validation Loss: 1.214 \n",
      "Epoch[9] Iteration[1000] Training Loss: 1.01\n",
      "Epoch[9] Validation Loss: 1.221 \n",
      "Epoch[9] Iteration[2000] Training Loss: 0.97\n",
      "Epoch[9] Validation Loss: 1.229 \n",
      "Epoch[9] Iteration[3000] Training Loss: 1.12\n",
      "Epoch[9] Validation Loss: 1.234 \n",
      "Epoch[9] Iteration[4000] Training Loss: 1.05\n",
      "Epoch[9] Validation Loss: 1.225 \n",
      "Epoch[9] Iteration[5000] Training Loss: 1.11\n",
      "Epoch[9] Validation Loss: 1.222 \n",
      "Epoch[9] Iteration[6000] Training Loss: 1.04\n",
      "Epoch[9] Validation Loss: 1.218 \n",
      "Epoch[9] Iteration[7000] Training Loss: 1.16\n",
      "Epoch[9] Validation Loss: 1.214 \n",
      "Epoch[10] Iteration[0] Training Loss: 0.80\n",
      "Epoch[10] Validation Loss: 1.217 \n",
      "Epoch[10] Iteration[1000] Training Loss: 0.80\n",
      "Epoch[10] Validation Loss: 1.225 \n",
      "Epoch[10] Iteration[2000] Training Loss: 0.79\n",
      "Epoch[10] Validation Loss: 1.231 \n",
      "Epoch[10] Iteration[3000] Training Loss: 1.14\n",
      "Epoch[10] Validation Loss: 1.229 \n",
      "Epoch[10] Iteration[4000] Training Loss: 1.16\n",
      "Epoch[10] Validation Loss: 1.225 \n",
      "Epoch[10] Iteration[5000] Training Loss: 1.03\n",
      "Epoch[10] Validation Loss: 1.221 \n",
      "Epoch[10] Iteration[6000] Training Loss: 1.10\n",
      "Epoch[10] Validation Loss: 1.223 \n",
      "Epoch[10] Iteration[7000] Training Loss: 1.14\n",
      "Epoch[10] Validation Loss: 1.223 \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "# This code utilizes ignite engine's create_supervised_trainer()\n",
    "# But we need something more basic\n",
    "\n",
    "# model = MF(n_user, n_item, k=k)\n",
    "# model = Bias_Only(n_user, n_item)\n",
    "\n",
    "# Experiment 1 - model = Alpha_Only()\n",
    "# Experiment 2 - model = Alpha_Theta()\n",
    "# Experiment 3 - model = MF_theta(n_user, n_place, k=k)\n",
    "\n",
    "model = MF_theta_betas_time(n_user, n_place, k=k)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=lamb)\n",
    "\n",
    "def chunks(X, Y, size):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    starts = list(range(0, len(X), size))\n",
    "    shuffle(starts)\n",
    "    for i in starts:\n",
    "        yield (X[i:i + size], Y[i:i + size])\n",
    "        \n",
    "# To keep track to best hyperparameters and results\n",
    "best_loss = 0\n",
    "best = []\n",
    "\n",
    "losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(10+1):\n",
    "    \n",
    "    i = 0\n",
    "    for feature, target in chunks(np.array(train_x), np.array(train_y), batch_size):\n",
    "        # This zeros the gradients on every parameter. \n",
    "        # This is easy to miss and hard to troubleshoot.\n",
    "        optimizer.zero_grad()\n",
    "        # Convert \n",
    "        feature = Variable(torch.from_numpy(feature))\n",
    "        target = Variable(torch.from_numpy(target).type(torch.FloatTensor))\n",
    "        \n",
    "        if cuda:\n",
    "            feature = feature.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        # model in training mode    \n",
    "        model.train()\n",
    "            \n",
    "        # Compute a prediction for these features\n",
    "        prediction = model.forward(feature)\n",
    "        # Compute a loss given what the true target outcome was\n",
    "        loss = model.loss(prediction, target)\n",
    "        # break\n",
    "        # Backpropagate: compute the direction / gradient every model parameter\n",
    "        # defined in your __init__ should move in in order to minimize this loss\n",
    "        # However, we're not actually changing these parameters, we're just storing\n",
    "        # how they should change.\n",
    "\n",
    "        loss.backward()\n",
    "        # Now take a step & update the model parameters. The optimizer uses the gradient at \n",
    "        # defined on every parameter in our model and nudges it in that direction.\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%1000 == 0 and epoch%1 == 0:\n",
    "            print(\"Epoch[{}] Iteration[{}] Training Loss: {:.2f}\".format(epoch, i, loss.data))\n",
    "\n",
    "        # Record the loss per example\n",
    "        losses.append(loss.cpu().data.numpy() / len(feature))\n",
    "        \n",
    "        if i%1000 == 0 and epoch%1 == 0:\n",
    "            \n",
    "            val_feature = torch.from_numpy(np.array(valid_x))\n",
    "            val_target = torch.from_numpy(np.array(valid_y)).type(torch.FloatTensor)\n",
    "            \n",
    "            if cuda:\n",
    "                val_feature = val_feature.cuda()\n",
    "                val_target = val_target.cuda()\n",
    "                \n",
    "            # model in test mode    \n",
    "            model.eval()\n",
    "\n",
    "            val_pred = model.forward(val_feature)\n",
    "            vloss = model.loss(val_pred, val_target)\n",
    "            print(\"Epoch[{}] Validation Loss: {:.3f} \".format(epoch, vloss.data))\n",
    "            \n",
    "            # Record the validation loss per example\n",
    "            valid_losses.append(vloss.cpu().data.numpy()/len(val_feature))\n",
    "            \n",
    "            if best_loss is 0:\n",
    "                best_loss = vloss\n",
    "                best = [vloss,lr,lamb]\n",
    "                print(\"Save best theta...\")\n",
    "            else:\n",
    "                if vloss < best_loss:\n",
    "                    best_loss = vloss\n",
    "                    best = [vloss,lr,lamb]\n",
    "                    print(\"Save best theta...\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.4290, device='cuda:0', grad_fn=<MseLossBackward>), 0.01, 1e-06]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alpha-only model --> alpha = mean\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0432], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.4249, device='cuda:0', grad_fn=<MseLossBackward>), 0.01, 1e-06]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alpha-Theta model --> alpha ~ mean, popularity has slight uplift to rating\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.0180], device='cuda:0')\n",
      "tensor([0.0014], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.bias.data)\n",
    "print(model.theta.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.2371, device='cuda:0', grad_fn=<MseLossBackward>), 0.01, 1e-06]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MF-Theta model --> Does not outperform MF(k=1) model\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.9391], device='cuda:0')\n",
      "tensor([0.0001], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.bias.data)\n",
    "print(model.theta.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.2135, device='cuda:0', grad_fn=<MseLossBackward>), 0.005, 5e-07]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MF-Theta-Betas-Time model --> Does not outperform MF(k=1) model\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1739], device='cuda:0')\n",
      "tensor([-0.0033], device='cuda:0')\n",
      "tensor([[1.0990],\n",
      "        [1.1457],\n",
      "        [1.1080],\n",
      "        [1.0896],\n",
      "        [1.0960],\n",
      "        [1.1721],\n",
      "        [1.1368],\n",
      "        [1.1319],\n",
      "        [1.1465],\n",
      "        [1.1177],\n",
      "        [1.0661],\n",
      "        [1.0872]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.bias.data)\n",
    "print(model.theta.data)\n",
    "print(model.bias_month.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
